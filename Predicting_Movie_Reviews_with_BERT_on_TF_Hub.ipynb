{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predicting Movie Reviews with BERT on TF Hub.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeKLTW/tf1/blob/master/Predicting_Movie_Reviews_with_BERT_on_TF_Hub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kkMQWqUOb-N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dfd66f94-fe1c-4c0f-b92c-647f574ae6d2"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from datetime import datetime"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0606 07:06:18.931993 139709332486016 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RE24HacFjYyo",
        "colab_type": "code",
        "outputId": "ba2b4bbb-b128-4081-a4fc-6c49a8c18a3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "! pip install bert_tensorflow"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert_tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert_tensorflow) (1.12.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0pFKbF1j_E2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2aKg2O_kpfu",
        "colab_type": "code",
        "outputId": "537ff84a-1a7a-48de-a2ab-90fa3bdfb0b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "OUTPUT_DIR = 'OUTPUT_DIR_NAME'\n",
        "try:\n",
        "    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
        "except:\n",
        "    pass\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: OUTPUT_DIR_NAME *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdWmDkCgxzkw",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "aclImdb\n",
        "├── README\n",
        "├── imdb.vocab\n",
        "├── imdbEr.txt\n",
        "├── test\n",
        "│   ├── labeledBow.feat\n",
        "│   ├── neg\n",
        "│   ├── pos\n",
        "│   ├── urls_neg.txt\n",
        "│   └── urls_pos.txt\n",
        "└── train\n",
        "    ├── labeledBow.feat\n",
        "    ├── neg\n",
        "    ├── pos\n",
        "    ├── unsup\n",
        "    ├── unsupBow.feat\n",
        "    ├── urls_neg.txt\n",
        "    ├── urls_pos.txt\n",
        "    └── urls_unsup.txt\n",
        "  \n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEpltVWOkqn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "import os\n",
        "import re\n",
        "\n",
        "def load_directory_data(directory):\n",
        "    data = {}\n",
        "    data[\"sentence\"] = []\n",
        "    data[\"sentiment\"] = []\n",
        "    \n",
        "    for file_path in os.listdir(directory):\n",
        "        with tf.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
        "            data[\"sentence\"].append(f.read())\n",
        "            data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
        "    data = pd.DataFrame.from_dict(data)\n",
        "    return data\n",
        "\n",
        "def load_dataset(directory):\n",
        "    pos_df = load_directory_data(os.path.join(directory,\"pos\"))\n",
        "    neg_df = load_directory_data(os.path.join(directory,\"neg\"))\n",
        "    pos_df['polarity'] = 1\n",
        "    neg_df['polarity'] = 0\n",
        "    data = pd.concat([pos_df, neg_df]).sample(frac=1.).reset_index(drop=True)\n",
        "    return data\n",
        "    \n",
        "def download_and_load_datasets(force_download=False):\n",
        "    dataset = keras.utils.get_file(fname=\"aclImdb.tar.gz\",\n",
        "                                   origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", extract=True)\n",
        "    train_df = load_dataset(os.path.join(os.path.dirname(dataset), \"aclImdb\", \"train\"))\n",
        "    test_df = load_dataset(os.path.join(os.path.dirname(dataset), \"aclImdb\", \"test\"))\n",
        "    return train_df, test_df\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adlDAJZak47v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "54a9eaa0-17ec-46c0-8c49-46b7e552249c"
      },
      "source": [
        "train_df, test_df = download_and_load_datasets()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 8s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVqnvG4wwd3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = train_df.sample(5000)\n",
        "test_data = test_df.sample(5000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqkOV5cnzT80",
        "colab_type": "code",
        "outputId": "d418bc61-98a1-4126-cd8a-f255110bd236",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7265</th>\n",
              "      <td>I thought the film could be a bit more complex...</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9057</th>\n",
              "      <td>We know that firefighters and rescue workers a...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6676</th>\n",
              "      <td>This is a good movie, but it is not recommende...</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22193</th>\n",
              "      <td>I found this film embarrassing to watch. I fel...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20079</th>\n",
              "      <td>I have yet to see a film with Nolte in it that...</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                sentence sentiment  polarity\n",
              "7265   I thought the film could be a bit more complex...         7         1\n",
              "9057   We know that firefighters and rescue workers a...         1         0\n",
              "6676   This is a good movie, but it is not recommende...        10         1\n",
              "22193  I found this film embarrassing to watch. I fel...         1         0\n",
              "20079  I have yet to see a film with Nolte in it that...         9         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71Lj4SWmztVy",
        "colab_type": "code",
        "outputId": "2bb0880c-9fdb-4c6f-ac48-9211fd0be45c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test_data.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13352</th>\n",
              "      <td>I had heard about \"gaming\" and \"Dungeons and D...</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3009</th>\n",
              "      <td>I have to admit I was deceived by the title an...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19758</th>\n",
              "      <td>This film proves you don't need a Hollywood bu...</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12578</th>\n",
              "      <td>Clouzot followed Le Corbeau, where no one knew...</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20794</th>\n",
              "      <td>I am pretty surprised to see that this movie e...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                sentence sentiment  polarity\n",
              "13352  I had heard about \"gaming\" and \"Dungeons and D...         9         1\n",
              "3009   I have to admit I was deceived by the title an...         2         0\n",
              "19758  This film proves you don't need a Hollywood bu...         9         1\n",
              "12578  Clouzot followed Le Corbeau, where no one knew...         9         1\n",
              "20794  I am pretty surprised to see that this movie e...         1         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9PX0YbHk5ec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_COLUMN = 'sentence'\n",
        "LABEL_COLUMN = 'polarity'\n",
        "label_list = [0,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUHSGjL8k5ph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# bert.run_classifier.InputExample\n",
        "train_input_example = train_data.apply(lambda x:bert.run_classifier.InputExample(guid=None, text_a = x[DATA_COLUMN], text_b=None,label=x[LABEL_COLUMN]),axis=1)\n",
        "test_input_example = test_data.apply(lambda x:bert.run_classifier.InputExample(guid=None, text_a = x[DATA_COLUMN], text_b=None,label=x[LABEL_COLUMN]),axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ccqq1ohk50w",
        "colab_type": "code",
        "outputId": "1dd948a7-1cb1-4b41-98d5-48675bdbcc66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "def create_tokenizer_from_hub_module():\n",
        "    with tf.Graph().as_default():\n",
        "        bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "        with tf.Session() as sess:\n",
        "            vocab_file, do_lower_case =sess.run([tokenization_info[\"vocab_file\"],tokenization_info[\"do_lower_case\"]])\n",
        "            \n",
        "            return bert.tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0606 07:07:14.784930 139709332486016 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:07:17.159623 139709332486016 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQmQiIU09UuC",
        "colab_type": "code",
        "outputId": "12ca40ab-b95f-4918-a3b1-44caccda5907",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "tokenizer.tokenize(\"This here's an example of using the BERT tokenizer\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this',\n",
              " 'here',\n",
              " \"'\",\n",
              " 's',\n",
              " 'an',\n",
              " 'example',\n",
              " 'of',\n",
              " 'using',\n",
              " 'the',\n",
              " 'bert',\n",
              " 'token',\n",
              " '##izer']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpIs_40w9lKS",
        "colab_type": "code",
        "outputId": "d739b604-0410-48f5-ac22-109987a4e7c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2502
        }
      },
      "source": [
        "MAX_SEQ_LENGTH = 128\n",
        "train_features = bert.run_classifier.convert_examples_to_features(train_input_example, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "test_features = bert.run_classifier.convert_examples_to_features(test_input_example, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "# This function is not used by this file but is still used by the Colab and people who depend on it.\n",
        "\n",
        "\"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
        "\"\"\"\n",
        "guid\n",
        "tokens\n",
        "input_ids\n",
        "input_mask\n",
        "segment_ids\n",
        "label\n",
        "\"\"\""
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.219772 139709332486016 run_classifier.py:774] Writing example 0 of 5000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.233097 139709332486016 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.237892 139709332486016 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i thought the film could be a bit more complex , in a psychological sense perhaps , but the action and voice acting were top notch . the animation was heavy c ##g in many scenes , but very good ones at that . this is one of the batman returns / forever type films , which include romance ##s and the conflicts of wayne and motives for dating . 00 ##7 fans would love this , and so would the females , great theme song ! wayne was portrayed very well in this film , and the pen ##quin was back to his true form , no mutant genes in him this time ! i liked the fact robin wasn ' t used too much [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.242017 139709332486016 run_classifier.py:464] tokens: [CLS] i thought the film could be a bit more complex , in a psychological sense perhaps , but the action and voice acting were top notch . the animation was heavy c ##g in many scenes , but very good ones at that . this is one of the batman returns / forever type films , which include romance ##s and the conflicts of wayne and motives for dating . 00 ##7 fans would love this , and so would the females , great theme song ! wayne was portrayed very well in this film , and the pen ##quin was back to his true form , no mutant genes in him this time ! i liked the fact robin wasn ' t used too much [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2245 1996 2143 2071 2022 1037 2978 2062 3375 1010 1999 1037 8317 3168 3383 1010 2021 1996 2895 1998 2376 3772 2020 2327 18624 1012 1996 7284 2001 3082 1039 2290 1999 2116 5019 1010 2021 2200 2204 3924 2012 2008 1012 2023 2003 2028 1997 1996 8942 5651 1013 5091 2828 3152 1010 2029 2421 7472 2015 1998 1996 9755 1997 6159 1998 17108 2005 5306 1012 4002 2581 4599 2052 2293 2023 1010 1998 2061 2052 1996 3801 1010 2307 4323 2299 999 6159 2001 6791 2200 2092 1999 2023 2143 1010 1998 1996 7279 12519 2001 2067 2000 2010 2995 2433 1010 2053 15527 9165 1999 2032 2023 2051 999 1045 4669 1996 2755 5863 2347 1005 1056 2109 2205 2172 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.245194 139709332486016 run_classifier.py:465] input_ids: 101 1045 2245 1996 2143 2071 2022 1037 2978 2062 3375 1010 1999 1037 8317 3168 3383 1010 2021 1996 2895 1998 2376 3772 2020 2327 18624 1012 1996 7284 2001 3082 1039 2290 1999 2116 5019 1010 2021 2200 2204 3924 2012 2008 1012 2023 2003 2028 1997 1996 8942 5651 1013 5091 2828 3152 1010 2029 2421 7472 2015 1998 1996 9755 1997 6159 1998 17108 2005 5306 1012 4002 2581 4599 2052 2293 2023 1010 1998 2061 2052 1996 3801 1010 2307 4323 2299 999 6159 2001 6791 2200 2092 1999 2023 2143 1010 1998 1996 7279 12519 2001 2067 2000 2010 2995 2433 1010 2053 15527 9165 1999 2032 2023 2051 999 1045 4669 1996 2755 5863 2347 1005 1056 2109 2205 2172 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.247422 139709332486016 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.250063 139709332486016 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.252775 139709332486016 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.260401 139709332486016 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.263768 139709332486016 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] we know that firefighters and rescue workers are heroes : an id ##ee rec ##ue few would challenge . friends and family of these and others who perished in the attacks on the world trade center might well be moved by this va ##pid play turned film . a sweet , earnest , though tongue - tied fire ##man recalls what he can of lost colleagues to a ben ##umb ##ed journalist who converts his fragments into a eu ##logy . they ponder the results . he mum ##bles some more , she compose ##s another eu ##logy , etc . , etc . < br / > < br / > the dreadful events that provoked the need for several thousand eu ##logies is overwhelmingly [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.266711 139709332486016 run_classifier.py:464] tokens: [CLS] we know that firefighters and rescue workers are heroes : an id ##ee rec ##ue few would challenge . friends and family of these and others who perished in the attacks on the world trade center might well be moved by this va ##pid play turned film . a sweet , earnest , though tongue - tied fire ##man recalls what he can of lost colleagues to a ben ##umb ##ed journalist who converts his fragments into a eu ##logy . they ponder the results . he mum ##bles some more , she compose ##s another eu ##logy , etc . , etc . < br / > < br / > the dreadful events that provoked the need for several thousand eu ##logies is overwhelmingly [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2057 2113 2008 21767 1998 5343 3667 2024 7348 1024 2019 8909 4402 28667 5657 2261 2052 4119 1012 2814 1998 2155 1997 2122 1998 2500 2040 23181 1999 1996 4491 2006 1996 2088 3119 2415 2453 2092 2022 2333 2011 2023 12436 23267 2377 2357 2143 1012 1037 4086 1010 17300 1010 2295 4416 1011 5079 2543 2386 17722 2054 2002 2064 1997 2439 8628 2000 1037 3841 25438 2098 4988 2040 19884 2010 10341 2046 1037 7327 6483 1012 2027 29211 1996 3463 1012 2002 12954 13510 2070 2062 1010 2016 17202 2015 2178 7327 6483 1010 4385 1012 1010 4385 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 21794 2824 2008 19157 1996 2342 2005 2195 4595 7327 21615 2003 24783 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.269151 139709332486016 run_classifier.py:465] input_ids: 101 2057 2113 2008 21767 1998 5343 3667 2024 7348 1024 2019 8909 4402 28667 5657 2261 2052 4119 1012 2814 1998 2155 1997 2122 1998 2500 2040 23181 1999 1996 4491 2006 1996 2088 3119 2415 2453 2092 2022 2333 2011 2023 12436 23267 2377 2357 2143 1012 1037 4086 1010 17300 1010 2295 4416 1011 5079 2543 2386 17722 2054 2002 2064 1997 2439 8628 2000 1037 3841 25438 2098 4988 2040 19884 2010 10341 2046 1037 7327 6483 1012 2027 29211 1996 3463 1012 2002 12954 13510 2070 2062 1010 2016 17202 2015 2178 7327 6483 1010 4385 1012 1010 4385 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 21794 2824 2008 19157 1996 2342 2005 2195 4595 7327 21615 2003 24783 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.272031 139709332486016 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.274753 139709332486016 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.277170 139709332486016 run_classifier.py:468] label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.284859 139709332486016 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.287942 139709332486016 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] this is a good movie , but it is not recommended if you don ' t like intelligent movies . it ' s about two guys that wish that the world would go away , and that ' s exactly what they get . the acting is great , the ending was not predictable , and it actually had a good story unlike most movies these days . people complain about the movie being too simple or too boring . i think they should just stick to movies like the toxic avenge ##r ( i actually like b movies ) or the grim adventures of billy and mandy . one note : if you notice this , this has exactly the same actors from cube except [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.290905 139709332486016 run_classifier.py:464] tokens: [CLS] this is a good movie , but it is not recommended if you don ' t like intelligent movies . it ' s about two guys that wish that the world would go away , and that ' s exactly what they get . the acting is great , the ending was not predictable , and it actually had a good story unlike most movies these days . people complain about the movie being too simple or too boring . i think they should just stick to movies like the toxic avenge ##r ( i actually like b movies ) or the grim adventures of billy and mandy . one note : if you notice this , this has exactly the same actors from cube except [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2023 2003 1037 2204 3185 1010 2021 2009 2003 2025 6749 2065 2017 2123 1005 1056 2066 9414 5691 1012 2009 1005 1055 2055 2048 4364 2008 4299 2008 1996 2088 2052 2175 2185 1010 1998 2008 1005 1055 3599 2054 2027 2131 1012 1996 3772 2003 2307 1010 1996 4566 2001 2025 21425 1010 1998 2009 2941 2018 1037 2204 2466 4406 2087 5691 2122 2420 1012 2111 17612 2055 1996 3185 2108 2205 3722 2030 2205 11771 1012 1045 2228 2027 2323 2074 6293 2000 5691 2066 1996 11704 24896 2099 1006 1045 2941 2066 1038 5691 1007 2030 1996 11844 7357 1997 5006 1998 18193 1012 2028 3602 1024 2065 2017 5060 2023 1010 2023 2038 3599 1996 2168 5889 2013 14291 3272 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.293426 139709332486016 run_classifier.py:465] input_ids: 101 2023 2003 1037 2204 3185 1010 2021 2009 2003 2025 6749 2065 2017 2123 1005 1056 2066 9414 5691 1012 2009 1005 1055 2055 2048 4364 2008 4299 2008 1996 2088 2052 2175 2185 1010 1998 2008 1005 1055 3599 2054 2027 2131 1012 1996 3772 2003 2307 1010 1996 4566 2001 2025 21425 1010 1998 2009 2941 2018 1037 2204 2466 4406 2087 5691 2122 2420 1012 2111 17612 2055 1996 3185 2108 2205 3722 2030 2205 11771 1012 1045 2228 2027 2323 2074 6293 2000 5691 2066 1996 11704 24896 2099 1006 1045 2941 2066 1038 5691 1007 2030 1996 11844 7357 1997 5006 1998 18193 1012 2028 3602 1024 2065 2017 5060 2023 1010 2023 2038 3599 1996 2168 5889 2013 14291 3272 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.296263 139709332486016 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.299055 139709332486016 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.301492 139709332486016 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.314047 139709332486016 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.317687 139709332486016 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i found this film embarrassing to watch . i felt like it was shoving the storyline down my throat as if i couldn ' t pick up the subtle ##ties i needed a voice over to spell them all out for me constantly . < br / > < br / > having a father who is still an alcoholic , i didn ' t really feel it was a film about alcoholism as such . alcoholic ##s , true alcoholic ##s are very lonely people inside , in my opinion of course . they find it hard to communicate , something that the main character had no problem with really , except he did have a problem saying i love you at one point - [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.320189 139709332486016 run_classifier.py:464] tokens: [CLS] i found this film embarrassing to watch . i felt like it was shoving the storyline down my throat as if i couldn ' t pick up the subtle ##ties i needed a voice over to spell them all out for me constantly . < br / > < br / > having a father who is still an alcoholic , i didn ' t really feel it was a film about alcoholism as such . alcoholic ##s , true alcoholic ##s are very lonely people inside , in my opinion of course . they find it hard to communicate , something that the main character had no problem with really , except he did have a problem saying i love you at one point - [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2179 2023 2143 16436 2000 3422 1012 1045 2371 2066 2009 2001 15866 1996 9994 2091 2026 3759 2004 2065 1045 2481 1005 1056 4060 2039 1996 11259 7368 1045 2734 1037 2376 2058 2000 6297 2068 2035 2041 2005 2033 7887 1012 1026 7987 1013 1028 1026 7987 1013 1028 2383 1037 2269 2040 2003 2145 2019 14813 1010 1045 2134 1005 1056 2428 2514 2009 2001 1037 2143 2055 25519 2004 2107 1012 14813 2015 1010 2995 14813 2015 2024 2200 9479 2111 2503 1010 1999 2026 5448 1997 2607 1012 2027 2424 2009 2524 2000 10639 1010 2242 2008 1996 2364 2839 2018 2053 3291 2007 2428 1010 3272 2002 2106 2031 1037 3291 3038 1045 2293 2017 2012 2028 2391 1011 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.323113 139709332486016 run_classifier.py:465] input_ids: 101 1045 2179 2023 2143 16436 2000 3422 1012 1045 2371 2066 2009 2001 15866 1996 9994 2091 2026 3759 2004 2065 1045 2481 1005 1056 4060 2039 1996 11259 7368 1045 2734 1037 2376 2058 2000 6297 2068 2035 2041 2005 2033 7887 1012 1026 7987 1013 1028 1026 7987 1013 1028 2383 1037 2269 2040 2003 2145 2019 14813 1010 1045 2134 1005 1056 2428 2514 2009 2001 1037 2143 2055 25519 2004 2107 1012 14813 2015 1010 2995 14813 2015 2024 2200 9479 2111 2503 1010 1999 2026 5448 1997 2607 1012 2027 2424 2009 2524 2000 10639 1010 2242 2008 1996 2364 2839 2018 2053 3291 2007 2428 1010 3272 2002 2106 2031 1037 3291 3038 1045 2293 2017 2012 2028 2391 1011 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.325469 139709332486016 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.328711 139709332486016 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.331561 139709332486016 run_classifier.py:468] label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.356908 139709332486016 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.360664 139709332486016 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i have yet to see a film with no ##lt ##e in it that i did not like . however , this being said , he ' s made a lot of films and i ' ve seen just a few . in my minds eye i am keeping the images of his performance here and the one in \" the thin red line \" . no ##lt ##e has a a full range of acting talents . when it ' s necessary to shout he roar ##s like a wounded lion . his best moments are the ones i treasure in actors : when he just em ##ote ##s through facial , hand and body gestures , without saying anything . having come to the [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.363744 139709332486016 run_classifier.py:464] tokens: [CLS] i have yet to see a film with no ##lt ##e in it that i did not like . however , this being said , he ' s made a lot of films and i ' ve seen just a few . in my minds eye i am keeping the images of his performance here and the one in \" the thin red line \" . no ##lt ##e has a a full range of acting talents . when it ' s necessary to shout he roar ##s like a wounded lion . his best moments are the ones i treasure in actors : when he just em ##ote ##s through facial , hand and body gestures , without saying anything . having come to the [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2031 2664 2000 2156 1037 2143 2007 2053 7096 2063 1999 2009 2008 1045 2106 2025 2066 1012 2174 1010 2023 2108 2056 1010 2002 1005 1055 2081 1037 2843 1997 3152 1998 1045 1005 2310 2464 2074 1037 2261 1012 1999 2026 9273 3239 1045 2572 4363 1996 4871 1997 2010 2836 2182 1998 1996 2028 1999 1000 1996 4857 2417 2240 1000 1012 2053 7096 2063 2038 1037 1037 2440 2846 1997 3772 11725 1012 2043 2009 1005 1055 4072 2000 11245 2002 11950 2015 2066 1037 5303 7006 1012 2010 2190 5312 2024 1996 3924 1045 8813 1999 5889 1024 2043 2002 2074 7861 12184 2015 2083 13268 1010 2192 1998 2303 18327 1010 2302 3038 2505 1012 2383 2272 2000 1996 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.367066 139709332486016 run_classifier.py:465] input_ids: 101 1045 2031 2664 2000 2156 1037 2143 2007 2053 7096 2063 1999 2009 2008 1045 2106 2025 2066 1012 2174 1010 2023 2108 2056 1010 2002 1005 1055 2081 1037 2843 1997 3152 1998 1045 1005 2310 2464 2074 1037 2261 1012 1999 2026 9273 3239 1045 2572 4363 1996 4871 1997 2010 2836 2182 1998 1996 2028 1999 1000 1996 4857 2417 2240 1000 1012 2053 7096 2063 2038 1037 1037 2440 2846 1997 3772 11725 1012 2043 2009 1005 1055 4072 2000 11245 2002 11950 2015 2066 1037 5303 7006 1012 2010 2190 5312 2024 1996 3924 1045 8813 1999 5889 1024 2043 2002 2074 7861 12184 2015 2083 13268 1010 2192 1998 2303 18327 1010 2302 3038 2505 1012 2383 2272 2000 1996 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.370167 139709332486016 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.372653 139709332486016 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:14.375379 139709332486016 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.573296 139709332486016 run_classifier.py:774] Writing example 0 of 5000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.578858 139709332486016 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.587261 139709332486016 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i had heard about \" gaming \" and \" dungeons and dragons \" before , but i had know idea it could be like what i saw in the \" gamer ##s : do ##rk ##ness rising . \" these guys are so funny and fun to watch . especially the guy who plays the \" bard \" or \" min ##strel \" or whatever , he has a gift for physical comedy and timing . there is so much background humor and energy in some of the scenes that make you really think that at least some of it was improvised there on set . the special effects needed to be worked on a bit , but i saw it at a convention last year [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.591977 139709332486016 run_classifier.py:464] tokens: [CLS] i had heard about \" gaming \" and \" dungeons and dragons \" before , but i had know idea it could be like what i saw in the \" gamer ##s : do ##rk ##ness rising . \" these guys are so funny and fun to watch . especially the guy who plays the \" bard \" or \" min ##strel \" or whatever , he has a gift for physical comedy and timing . there is so much background humor and energy in some of the scenes that make you really think that at least some of it was improvised there on set . the special effects needed to be worked on a bit , but i saw it at a convention last year [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2018 2657 2055 1000 10355 1000 1998 1000 20264 1998 8626 1000 2077 1010 2021 1045 2018 2113 2801 2009 2071 2022 2066 2054 1045 2387 1999 1996 1000 27911 2015 1024 2079 8024 2791 4803 1012 1000 2122 4364 2024 2061 6057 1998 4569 2000 3422 1012 2926 1996 3124 2040 3248 1996 1000 22759 1000 2030 1000 8117 26877 1000 2030 3649 1010 2002 2038 1037 5592 2005 3558 4038 1998 10984 1012 2045 2003 2061 2172 4281 8562 1998 2943 1999 2070 1997 1996 5019 2008 2191 2017 2428 2228 2008 2012 2560 2070 1997 2009 2001 19641 2045 2006 2275 1012 1996 2569 3896 2734 2000 2022 2499 2006 1037 2978 1010 2021 1045 2387 2009 2012 1037 4680 2197 2095 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.594994 139709332486016 run_classifier.py:465] input_ids: 101 1045 2018 2657 2055 1000 10355 1000 1998 1000 20264 1998 8626 1000 2077 1010 2021 1045 2018 2113 2801 2009 2071 2022 2066 2054 1045 2387 1999 1996 1000 27911 2015 1024 2079 8024 2791 4803 1012 1000 2122 4364 2024 2061 6057 1998 4569 2000 3422 1012 2926 1996 3124 2040 3248 1996 1000 22759 1000 2030 1000 8117 26877 1000 2030 3649 1010 2002 2038 1037 5592 2005 3558 4038 1998 10984 1012 2045 2003 2061 2172 4281 8562 1998 2943 1999 2070 1997 1996 5019 2008 2191 2017 2428 2228 2008 2012 2560 2070 1997 2009 2001 19641 2045 2006 2275 1012 1996 2569 3896 2734 2000 2022 2499 2006 1037 2978 1010 2021 1045 2387 2009 2012 1037 4680 2197 2095 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.597013 139709332486016 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.599179 139709332486016 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.602781 139709332486016 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.607817 139709332486016 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.611432 139709332486016 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i have to admit i was dec ##ei ##ved by the title and the summary on the back of the box . so i popped it in the vc ##r and kept waiting . . . and waiting . . . and waiting for something good to happen . but of course , it never does . the makers of this film should be tied to a chair and made to watch \" saving private ryan \" . maybe they would learn something . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.613510 139709332486016 run_classifier.py:464] tokens: [CLS] i have to admit i was dec ##ei ##ved by the title and the summary on the back of the box . so i popped it in the vc ##r and kept waiting . . . and waiting . . . and waiting for something good to happen . but of course , it never does . the makers of this film should be tied to a chair and made to watch \" saving private ryan \" . maybe they would learn something . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2031 2000 6449 1045 2001 11703 7416 7178 2011 1996 2516 1998 1996 12654 2006 1996 2067 1997 1996 3482 1012 2061 1045 10538 2009 1999 1996 18315 2099 1998 2921 3403 1012 1012 1012 1998 3403 1012 1012 1012 1998 3403 2005 2242 2204 2000 4148 1012 2021 1997 2607 1010 2009 2196 2515 1012 1996 11153 1997 2023 2143 2323 2022 5079 2000 1037 3242 1998 2081 2000 3422 1000 7494 2797 4575 1000 1012 2672 2027 2052 4553 2242 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.616789 139709332486016 run_classifier.py:465] input_ids: 101 1045 2031 2000 6449 1045 2001 11703 7416 7178 2011 1996 2516 1998 1996 12654 2006 1996 2067 1997 1996 3482 1012 2061 1045 10538 2009 1999 1996 18315 2099 1998 2921 3403 1012 1012 1012 1998 3403 1012 1012 1012 1998 3403 2005 2242 2204 2000 4148 1012 2021 1997 2607 1010 2009 2196 2515 1012 1996 11153 1997 2023 2143 2323 2022 5079 2000 1037 3242 1998 2081 2000 3422 1000 7494 2797 4575 1000 1012 2672 2027 2052 4553 2242 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.619470 139709332486016 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.621757 139709332486016 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.623898 139709332486016 run_classifier.py:468] label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.632828 139709332486016 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.635364 139709332486016 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] this film proves you don ' t need a hollywood budget to make something fun to watch . what stuck with me is how the crew from different locations was able to pull together with no promises of riches to make something just because they believed in it . i think anybody who makes low budget movies can relate to certain scenes such as actors who just can ' t get that one line , being bothered by the police , and having most of the crew disappear after the first week . nobody got paid for this which says a lot for the people who had to travel cross country and for the long hours spent editing . after watching stu ##ie sell his personal [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.637876 139709332486016 run_classifier.py:464] tokens: [CLS] this film proves you don ' t need a hollywood budget to make something fun to watch . what stuck with me is how the crew from different locations was able to pull together with no promises of riches to make something just because they believed in it . i think anybody who makes low budget movies can relate to certain scenes such as actors who just can ' t get that one line , being bothered by the police , and having most of the crew disappear after the first week . nobody got paid for this which says a lot for the people who had to travel cross country and for the long hours spent editing . after watching stu ##ie sell his personal [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2023 2143 16481 2017 2123 1005 1056 2342 1037 5365 5166 2000 2191 2242 4569 2000 3422 1012 2054 5881 2007 2033 2003 2129 1996 3626 2013 2367 5269 2001 2583 2000 4139 2362 2007 2053 10659 1997 26768 2000 2191 2242 2074 2138 2027 3373 1999 2009 1012 1045 2228 10334 2040 3084 2659 5166 5691 2064 14396 2000 3056 5019 2107 2004 5889 2040 2074 2064 1005 1056 2131 2008 2028 2240 1010 2108 11250 2011 1996 2610 1010 1998 2383 2087 1997 1996 3626 10436 2044 1996 2034 2733 1012 6343 2288 3825 2005 2023 2029 2758 1037 2843 2005 1996 2111 2040 2018 2000 3604 2892 2406 1998 2005 1996 2146 2847 2985 9260 1012 2044 3666 24646 2666 5271 2010 3167 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.640109 139709332486016 run_classifier.py:465] input_ids: 101 2023 2143 16481 2017 2123 1005 1056 2342 1037 5365 5166 2000 2191 2242 4569 2000 3422 1012 2054 5881 2007 2033 2003 2129 1996 3626 2013 2367 5269 2001 2583 2000 4139 2362 2007 2053 10659 1997 26768 2000 2191 2242 2074 2138 2027 3373 1999 2009 1012 1045 2228 10334 2040 3084 2659 5166 5691 2064 14396 2000 3056 5019 2107 2004 5889 2040 2074 2064 1005 1056 2131 2008 2028 2240 1010 2108 11250 2011 1996 2610 1010 1998 2383 2087 1997 1996 3626 10436 2044 1996 2034 2733 1012 6343 2288 3825 2005 2023 2029 2758 1037 2843 2005 1996 2111 2040 2018 2000 3604 2892 2406 1998 2005 1996 2146 2847 2985 9260 1012 2044 3666 24646 2666 5271 2010 3167 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.642968 139709332486016 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.644885 139709332486016 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.647096 139709332486016 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.660102 139709332486016 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.663457 139709332486016 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] cl ##ou ##zo ##t followed le co ##rb ##eau , where no one knew who was penn ##ing the poison thus everyone was suspected , with another masterpiece , qu ##ai des or ##fe ##vres four years later in which we know from the outset ( or think we do ) who ##dun ##ni ##t . top - billed louis jo ##uve ##t doesn ' t appear for forty minutes by which time cl ##ou ##zo ##t has established a rich mil ##ieu of music hall , music publishers , etc and a fine cast of colourful characters ; angela lan ##sbury look ##ali ##ke ( lan ##sbury appeared in woman of paris that same year ) suzy del ##air scores as the chant ##eus ##e [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.666357 139709332486016 run_classifier.py:464] tokens: [CLS] cl ##ou ##zo ##t followed le co ##rb ##eau , where no one knew who was penn ##ing the poison thus everyone was suspected , with another masterpiece , qu ##ai des or ##fe ##vres four years later in which we know from the outset ( or think we do ) who ##dun ##ni ##t . top - billed louis jo ##uve ##t doesn ' t appear for forty minutes by which time cl ##ou ##zo ##t has established a rich mil ##ieu of music hall , music publishers , etc and a fine cast of colourful characters ; angela lan ##sbury look ##ali ##ke ( lan ##sbury appeared in woman of paris that same year ) suzy del ##air scores as the chant ##eus ##e [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 18856 7140 6844 2102 2628 3393 2522 15185 10207 1010 2073 2053 2028 2354 2040 2001 9502 2075 1996 9947 2947 3071 2001 6878 1010 2007 2178 17743 1010 24209 4886 4078 2030 7959 24790 2176 2086 2101 1999 2029 2057 2113 2013 1996 26674 1006 2030 2228 2057 2079 1007 2040 27584 3490 2102 1012 2327 1011 14843 3434 8183 22909 2102 2987 1005 1056 3711 2005 5659 2781 2011 2029 2051 18856 7140 6844 2102 2038 2511 1037 4138 23689 17301 1997 2189 2534 1010 2189 8544 1010 4385 1998 1037 2986 3459 1997 26102 3494 1025 10413 17595 18065 2298 11475 3489 1006 17595 18065 2596 1999 2450 1997 3000 2008 2168 2095 1007 28722 3972 11215 7644 2004 1996 16883 10600 2063 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.668679 139709332486016 run_classifier.py:465] input_ids: 101 18856 7140 6844 2102 2628 3393 2522 15185 10207 1010 2073 2053 2028 2354 2040 2001 9502 2075 1996 9947 2947 3071 2001 6878 1010 2007 2178 17743 1010 24209 4886 4078 2030 7959 24790 2176 2086 2101 1999 2029 2057 2113 2013 1996 26674 1006 2030 2228 2057 2079 1007 2040 27584 3490 2102 1012 2327 1011 14843 3434 8183 22909 2102 2987 1005 1056 3711 2005 5659 2781 2011 2029 2051 18856 7140 6844 2102 2038 2511 1037 4138 23689 17301 1997 2189 2534 1010 2189 8544 1010 4385 1998 1037 2986 3459 1997 26102 3494 1025 10413 17595 18065 2298 11475 3489 1006 17595 18065 2596 1999 2450 1997 3000 2008 2168 2095 1007 28722 3972 11215 7644 2004 1996 16883 10600 2063 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.670922 139709332486016 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.673458 139709332486016 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.675326 139709332486016 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.684268 139709332486016 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.687460 139709332486016 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i am pretty surprised to see that this movie earned even luke ##war ##m reviews , i found this movie down ##right awful . the plot fl ##ound ##ers around trying to decide if it is a comedy or a thriller , then realizes it cannot achieve either . so it throws in the towel and continues with its absurd plot highlighted with a un ##int ##ent ##ional hilarious scene with laura lin ##ney , an injection , and spilled coffee that leaves the audience awkwardly sq ##ui ##rmin ##g in their seats looking at one another like is this for real ? basically it is ab ##ys ##mal and really disappointing for robin williams fans , and it makes you think someone blackmail ##ed laura [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.690498 139709332486016 run_classifier.py:464] tokens: [CLS] i am pretty surprised to see that this movie earned even luke ##war ##m reviews , i found this movie down ##right awful . the plot fl ##ound ##ers around trying to decide if it is a comedy or a thriller , then realizes it cannot achieve either . so it throws in the towel and continues with its absurd plot highlighted with a un ##int ##ent ##ional hilarious scene with laura lin ##ney , an injection , and spilled coffee that leaves the audience awkwardly sq ##ui ##rmin ##g in their seats looking at one another like is this for real ? basically it is ab ##ys ##mal and really disappointing for robin williams fans , and it makes you think someone blackmail ##ed laura [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2572 3492 4527 2000 2156 2008 2023 3185 3687 2130 5355 9028 2213 4391 1010 1045 2179 2023 3185 2091 15950 9643 1012 1996 5436 13109 28819 2545 2105 2667 2000 5630 2065 2009 2003 1037 4038 2030 1037 10874 1010 2059 10919 2009 3685 6162 2593 1012 2061 2009 11618 1999 1996 10257 1998 4247 2007 2049 18691 5436 11548 2007 1037 4895 18447 4765 19301 26316 3496 2007 6874 11409 5420 1010 2019 13341 1010 1998 13439 4157 2008 3727 1996 4378 18822 5490 10179 27512 2290 1999 2037 4272 2559 2012 2028 2178 2066 2003 2023 2005 2613 1029 10468 2009 2003 11113 7274 9067 1998 2428 15640 2005 5863 3766 4599 1010 1998 2009 3084 2017 2228 2619 25044 2098 6874 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.692402 139709332486016 run_classifier.py:465] input_ids: 101 1045 2572 3492 4527 2000 2156 2008 2023 3185 3687 2130 5355 9028 2213 4391 1010 1045 2179 2023 3185 2091 15950 9643 1012 1996 5436 13109 28819 2545 2105 2667 2000 5630 2065 2009 2003 1037 4038 2030 1037 10874 1010 2059 10919 2009 3685 6162 2593 1012 2061 2009 11618 1999 1996 10257 1998 4247 2007 2049 18691 5436 11548 2007 1037 4895 18447 4765 19301 26316 3496 2007 6874 11409 5420 1010 2019 13341 1010 1998 13439 4157 2008 3727 1996 4378 18822 5490 10179 27512 2290 1999 2037 4272 2559 2012 2028 2178 2066 2003 2023 2005 2613 1029 10468 2009 2003 11113 7274 9067 1998 2428 15640 2005 5863 3766 4599 1010 1998 2009 3084 2017 2228 2619 25044 2098 6874 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.694756 139709332486016 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.696974 139709332486016 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:09:41.699825 139709332486016 run_classifier.py:468] label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nguid\\ntokens\\ninput_ids\\ninput_mask\\nsegment_ids\\nlabel\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KejM3gP2PsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create model\n",
        "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels, num_labels):\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB, trainable=True)\n",
        "    \n",
        "    bert_inputs = dict(input_ids=input_ids, input_mask= input_mask, segment_ids=segment_ids)\n",
        "    \n",
        "    bert_outputs = bert_module(inputs=bert_inputs, signature='tokens',as_dict=True)\n",
        "    \n",
        "    output_layer = bert_outputs['pooled_output']\n",
        "    \n",
        "    hidden_size = output_layer.shape[-1].value\n",
        "    \n",
        "    output_weights = tf.get_variable('output_weights', [num_labels,hidden_size],initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "    output_bias = tf.get_variable('output_bias', [num_labels],initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "    \n",
        "    # define loss function\n",
        "    with tf.variable_scope(\"loss\"):\n",
        "        output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "        \n",
        "        logits = tf.matmul(output_layer,output_weights, transpose_b=True)\n",
        "        logits = tf.nn.bias_add(logits,output_bias)\n",
        "        log_probs = tf.nn.log_softmax(logits, axis=-1) #logit not logarithmic\n",
        "        \n",
        "        one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "        predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "        \n",
        "        if is_predicting:\n",
        "            return (predicted_labels, log_probs)\n",
        "        \n",
        "        per_example_loss = tf.reduce_sum(one_hot_labels*log_probs, axis=-1)\n",
        "        loss = tf.reduce_mean(per_example_loss)\n",
        "        return (loss,predicted_labels, log_probs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf4ngDps39Gk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_fn_builder(num_labels, learning_rate, num_train_steps,num_warmup_steps):\n",
        "    def model_fn(features, labels, mode, params):\n",
        "        input_ids = features[\"input_ids\"]\n",
        "        input_mask = features[\"input_mask\"]\n",
        "        segment_ids = features[\"segment_ids\"]\n",
        "        label_ids = features[\"label_ids\"]\n",
        "\n",
        "\n",
        "        \n",
        "        is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "        \n",
        "        if not is_predicting:\n",
        "            (loss,predicted_labels,log_probs) = create_model(is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "            \n",
        "            train_op = bert.optimization.create_optimizer(loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "            \n",
        "            def metric_fn(label_ids, predicted_labels):\n",
        "                \n",
        "                accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "                f1_score = tf.contrib.metrics.f1_score(label_ids, predicted_labels)\n",
        "                auc = tf.metrics.auc(label_ids, predicted_labels)\n",
        "                recall = tf.metrics.recall(label_ids, predicted_labels)\n",
        "                precision = tf.metrics.precision(label_ids, predicted_labels)\n",
        "                true_positive = tf.metrics.true_positives(label_ids, predicted_labels)\n",
        "                true_negative = tf.metrics.true_negatives(label_ids, predicted_labels)\n",
        "                false_positive = tf.metrics.false_positives(label_ids, predicted_labels)\n",
        "                false_negative = tf.metrics.false_negatives(label_ids, predicted_labels)\n",
        "                return {\"accuracy\":accuracy,\n",
        "                       \"f1_score\":f1_score,\n",
        "                       \"auc\": auc,\n",
        "                       \"precision\":precision,\n",
        "                       \"true_positive\":true_positive,\n",
        "                       \"true_negative\":true_negative,\n",
        "                       \"false_positive\": false_positive,\n",
        "                       \"false_negative\": false_negative\n",
        "                       }            \n",
        "            eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "            \n",
        "            if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "                \n",
        "                return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
        "            else:\n",
        "                return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metrics)\n",
        "        else:\n",
        "            (loss,predicted_labels, log_probs) = create_model(is_predicting, input_ids, input_mask, segment_ids, labels, num_labels)\n",
        "            predictions = {'probabilities':log_probs, 'labels':predicted_labels}\n",
        "    \n",
        "    return model_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQZXRc3f9T5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAINING_EPOCHS = 10\n",
        "\n",
        "# warm up\n",
        "\n",
        "WARMUP_PROPORTION = 0.1\n",
        "SAVE_CHECKPOINT_STEPS = 500\n",
        "SAVE_SUMMARY_STEPS = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uiHwwsj3ykx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_train_steps = int(len(train_features)/ BATCH_SIZE * NUM_TRAINING_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps* WARMUP_PROPORTION)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RKX_wSc20TA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run_config = tf.estimator.RunConfig(model_dir=OUTPUT_DIR, \n",
        "                                    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "                                    save_checkpoints_steps= SAVE_CHECKPOINT_STEPS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBlood8w3GFq",
        "colab_type": "code",
        "outputId": "6ddbc518-6de6-4bfc-f40c-936096aef51d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "model_fn = model_fn_builder(num_labels=len(label_list), \n",
        "                            learning_rate=LEARNING_RATE, \n",
        "                            num_train_steps=num_train_steps, \n",
        "                            num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "estimator = tf.estimator.Estimator(model_fn=model_fn, \n",
        "                                   config=run_config,\n",
        "                                   params={\"batch_size\": BATCH_SIZE})"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'OUTPUT_DIR_NAME', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f10637f62b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:10:26.452908 139709332486016 estimator.py:201] Using config: {'_model_dir': 'OUTPUT_DIR_NAME', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f10637f62b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf9oCtj04L0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_input_fn = bert.run_classifier.input_fn_builder(\n",
        "    features=train_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsff40ULhdaX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "outputId": "28d0228a-3270-447e-b604-ed08ab71e80a"
      },
      "source": [
        "print(f'Beginning Training!')\n",
        "current_time = datetime.now()\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print(\"Training took time \", datetime.now() - current_time)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning Training!\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:11:00.878042 139709332486016 estimator.py:1111] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:11:04.435531 139709332486016 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-18-110b9c9c9525>:17: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0606 07:11:04.577568 139709332486016 deprecation.py:506] From <ipython-input-18-110b9c9c9525>:17: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0606 07:11:04.630394 139709332486016 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0606 07:11:04.724097 139709332486016 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0606 07:11:13.809013 139709332486016 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:11:16.539942 139709332486016 estimator.py:1113] Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:11:16.543991 139709332486016 basic_session_run_hooks.py:527] Create CheckpointSaverHook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:11:20.349627 139709332486016 monitored_session.py:222] Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:11:26.645232 139709332486016 session_manager.py:491] Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:11:26.917134 139709332486016 session_manager.py:493] Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into OUTPUT_DIR_NAME/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:11:38.325304 139709332486016 basic_session_run_hooks.py:594] Saving checkpoints for 0 into OUTPUT_DIR_NAME/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = -0.7185857, step = 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:12:42.549192 139709332486016 basic_session_run_hooks.py:249] loss = -0.7185857, step = 1\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfQDAh1nmFMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_input_fn = run_classifier.input_fn_builder(\n",
        "    features=test_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SyhH0Xf-MOU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "15d83f46-c3ae-4c5d-a9e6-063b49308577"
      },
      "source": [
        "estimator.evaluate(input_fn=test_input_fn, steps=None)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:02:44.565648 139892431648640 estimator.py:1111] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:02:49.202524 139892431648640 saver.py:1483] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:02:59.392361 139892431648640 estimator.py:1113] Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2019-06-06T07:02:59Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:02:59.416809 139892431648640 evaluation.py:257] Starting evaluation at 2019-06-06T07:02:59Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:03:00.885173 139892431648640 monitored_session.py:222] Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0606 07:03:00.888698 139892431648640 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from OUTPUT_DIR_NAME/model.ckpt-468\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:03:00.894531 139892431648640 saver.py:1270] Restoring parameters from OUTPUT_DIR_NAME/model.ckpt-468\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:03:03.689174 139892431648640 session_manager.py:491] Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:03:03.990406 139892431648640 session_manager.py:493] Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2019-06-06-07:03:51\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:03:51.151027 139892431648640 evaluation.py:277] Finished evaluation at 2019-06-06-07:03:51\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 468: accuracy = 0.5028, auc = 0.5, f1_score = 0.6691508, false_negative = 0.0, false_positive = 2486.0, global_step = 468, loss = -15.961964, precision = 0.5028, true_negative = 0.0, true_positive = 2514.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:03:51.153890 139892431648640 estimator.py:1979] Saving dict for global step 468: accuracy = 0.5028, auc = 0.5, f1_score = 0.6691508, false_negative = 0.0, false_positive = 2486.0, global_step = 468, loss = -15.961964, precision = 0.5028, true_negative = 0.0, true_positive = 2514.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 468: OUTPUT_DIR_NAME/model.ckpt-468\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 07:03:54.678534 139892431648640 estimator.py:2039] Saving 'checkpoint_path' summary for global step 468: OUTPUT_DIR_NAME/model.ckpt-468\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.5028,\n",
              " 'auc': 0.5,\n",
              " 'f1_score': 0.6691508,\n",
              " 'false_negative': 0.0,\n",
              " 'false_positive': 2486.0,\n",
              " 'global_step': 468,\n",
              " 'loss': -15.961964,\n",
              " 'precision': 0.5028,\n",
              " 'true_negative': 0.0,\n",
              " 'true_positive': 2514.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYOxfbpU-PLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIP5yKfmY14a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}