{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predicting Movie Reviews with BERT on TF Hub.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeKLTW/tf1/blob/master/Predicting_Movie_Reviews_with_BERT_on_TF_Hub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kkMQWqUOb-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from datetime import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RE24HacFjYyo",
        "colab_type": "code",
        "outputId": "9decefa7-f0a1-4573-e374-130c51db1dfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "! pip install bert_tensorflow"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert_tensorflow in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert_tensorflow) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0pFKbF1j_E2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2aKg2O_kpfu",
        "colab_type": "code",
        "outputId": "8f0b263e-4eed-4825-876e-df980e708edf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "OUTPUT_DIR = 'OUTPUT_DIR_NAME'\n",
        "try:\n",
        "    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
        "except:\n",
        "    pass\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: OUTPUT_DIR_NAME *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdWmDkCgxzkw",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "aclImdb\n",
        "├── README\n",
        "├── imdb.vocab\n",
        "├── imdbEr.txt\n",
        "├── test\n",
        "│   ├── labeledBow.feat\n",
        "│   ├── neg\n",
        "│   ├── pos\n",
        "│   ├── urls_neg.txt\n",
        "│   └── urls_pos.txt\n",
        "└── train\n",
        "    ├── labeledBow.feat\n",
        "    ├── neg\n",
        "    ├── pos\n",
        "    ├── unsup\n",
        "    ├── unsupBow.feat\n",
        "    ├── urls_neg.txt\n",
        "    ├── urls_pos.txt\n",
        "    └── urls_unsup.txt\n",
        "  \n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEpltVWOkqn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "import os\n",
        "import re\n",
        "\n",
        "def load_directory_data(directory):\n",
        "    data = {}\n",
        "    data[\"sentence\"] = []\n",
        "    data[\"sentiment\"] = []\n",
        "    \n",
        "    for file_path in os.listdir(directory):\n",
        "        with tf.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
        "            data[\"sentence\"].append(f.read())\n",
        "            data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
        "    data = pd.DataFrame.from_dict(data)\n",
        "    return data\n",
        "\n",
        "def load_dataset(directory):\n",
        "    pos_df = load_directory_data(os.path.join(directory,\"pos\"))\n",
        "    neg_df = load_directory_data(os.path.join(directory,\"neg\"))\n",
        "    pos_df['polarity'] = 1\n",
        "    neg_df['polarity'] = 0\n",
        "    data = pd.concat([pos_df, neg_df]).sample(frac=1.).reset_index(drop=True)\n",
        "    return data\n",
        "    \n",
        "def download_and_load_datasets(force_download=False):\n",
        "    dataset = keras.utils.get_file(fname=\"aclImdb.tar.gz\",\n",
        "                                   origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", extract=True)\n",
        "    train_df = load_dataset(os.path.join(os.path.dirname(dataset), \"aclImdb\", \"train\"))\n",
        "    test_df = load_dataset(os.path.join(os.path.dirname(dataset), \"aclImdb\", \"test\"))\n",
        "    return train_df, test_df\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adlDAJZak47v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df, test_df = download_and_load_datasets()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVqnvG4wwd3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = train_df.sample(5000)\n",
        "test_data = test_df.sample(5000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqkOV5cnzT80",
        "colab_type": "code",
        "outputId": "64315db5-68c5-4901-f201-9a3ffb08fb12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23704</th>\n",
              "      <td>Eight academy nominations? It's beyond belief....</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24236</th>\n",
              "      <td>Pretty poor Firestarter clone that seems more ...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5644</th>\n",
              "      <td>This show has been my escape from reality for ...</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14854</th>\n",
              "      <td>Not a `woman film' but film for the gang. One ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17105</th>\n",
              "      <td>I can't understand why so many peoples praised...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                sentence sentiment  polarity\n",
              "23704  Eight academy nominations? It's beyond belief....         3         0\n",
              "24236  Pretty poor Firestarter clone that seems more ...         3         0\n",
              "5644   This show has been my escape from reality for ...        10         1\n",
              "14854  Not a `woman film' but film for the gang. One ...         1         0\n",
              "17105  I can't understand why so many peoples praised...         1         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71Lj4SWmztVy",
        "colab_type": "code",
        "outputId": "5456bbe5-dfa6-4d88-c0fa-2497cd5d4806",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test_data.head()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5053</th>\n",
              "      <td>The unthinkable has happened. Having first wit...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12498</th>\n",
              "      <td>I have to admit that I had low expectations fo...</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18066</th>\n",
              "      <td>I HATE MOVIES THAT END LIKE THIS!!!!&lt;br /&gt;&lt;br ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3363</th>\n",
              "      <td>I was invited to view this film at a small art...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20920</th>\n",
              "      <td>I finally got hold of Lifeforce on DVD with th...</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                sentence sentiment  polarity\n",
              "5053   The unthinkable has happened. Having first wit...         1         0\n",
              "12498  I have to admit that I had low expectations fo...         8         1\n",
              "18066  I HATE MOVIES THAT END LIKE THIS!!!!<br /><br ...         1         0\n",
              "3363   I was invited to view this film at a small art...         2         0\n",
              "20920  I finally got hold of Lifeforce on DVD with th...         7         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9PX0YbHk5ec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_COLUMN = 'sentence'\n",
        "LABEL_COLUMN = 'polarity'\n",
        "label_list = [0,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUHSGjL8k5ph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# bert.run_classifier.InputExample\n",
        "train_input_example = train_data.apply(lambda x:bert.run_classifier.InputExample(guid=None, text_a = x[DATA_COLUMN], text_b=None,label=x[LABEL_COLUMN]),axis=1)\n",
        "test_input_example = test_data.apply(lambda x:bert.run_classifier.InputExample(guid=None, text_a = x[DATA_COLUMN], text_b=None,label=x[LABEL_COLUMN]),axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ccqq1ohk50w",
        "colab_type": "code",
        "outputId": "4095e42d-b8ff-461b-f815-2a0e82bf3963",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "def create_tokenizer_from_hub_module():\n",
        "    with tf.Graph().as_default():\n",
        "        bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "        with tf.Session() as sess:\n",
        "            vocab_file, do_lower_case =sess.run([tokenization_info[\"vocab_file\"],tokenization_info[\"do_lower_case\"]])\n",
        "            \n",
        "            return bert.tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:30:20.238013 139892431648640 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQmQiIU09UuC",
        "colab_type": "code",
        "outputId": "f67dbeac-1085-4c70-bb60-cb3d8736b663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "tokenizer.tokenize(\"This here's an example of using the BERT tokenizer\")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this',\n",
              " 'here',\n",
              " \"'\",\n",
              " 's',\n",
              " 'an',\n",
              " 'example',\n",
              " 'of',\n",
              " 'using',\n",
              " 'the',\n",
              " 'bert',\n",
              " 'token',\n",
              " '##izer']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpIs_40w9lKS",
        "colab_type": "code",
        "outputId": "c0e3539c-3335-454b-9575-138c82da5b11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2502
        }
      },
      "source": [
        "MAX_SEQ_LENGTH = 128\n",
        "train_features = bert.run_classifier.convert_examples_to_features(train_input_example, label_list, MAX_SEQ_LEN, tokenizer)\n",
        "test_features = bert.run_classifier.convert_examples_to_features(test_input_example, label_list, MAX_SEQ_LEN, tokenizer)\n",
        "# This function is not used by this file but is still used by the Colab and people who depend on it.\n",
        "\n",
        "\"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
        "\"\"\"\n",
        "guid\n",
        "tokens\n",
        "input_ids\n",
        "input_mask\n",
        "segment_ids\n",
        "label\n",
        "\"\"\""
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.334294 139892431648640 run_classifier.py:774] Writing example 0 of 5000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.355544 139892431648640 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.356971 139892431648640 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] eight academy nominations ? it ' s beyond belief . i can only think it was a very bad year - even by hollywood standards . with hu ##ston as director and jack nicholson and kathleen turner as leads i probably would have swallowed the bait and watched this anyway , but the oscar nominations really sold it to me , and i feel distinctly cheated as a result . < br / > < br / > so it ' s a black comedy is it ? can anyone tell me where the humour is in pri ##zzi ' s honor ? it ' s certainly taste ##less ( the shooting in the head of a policeman ' s wife is but another supposedly comic [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.359947 139892431648640 run_classifier.py:464] tokens: [CLS] eight academy nominations ? it ' s beyond belief . i can only think it was a very bad year - even by hollywood standards . with hu ##ston as director and jack nicholson and kathleen turner as leads i probably would have swallowed the bait and watched this anyway , but the oscar nominations really sold it to me , and i feel distinctly cheated as a result . < br / > < br / > so it ' s a black comedy is it ? can anyone tell me where the humour is in pri ##zzi ' s honor ? it ' s certainly taste ##less ( the shooting in the head of a policeman ' s wife is but another supposedly comic [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2809 2914 9930 1029 2009 1005 1055 3458 6772 1012 1045 2064 2069 2228 2009 2001 1037 2200 2919 2095 1011 2130 2011 5365 4781 1012 2007 15876 7106 2004 2472 1998 2990 16955 1998 14559 6769 2004 5260 1045 2763 2052 2031 7351 1996 17395 1998 3427 2023 4312 1010 2021 1996 7436 9930 2428 2853 2009 2000 2033 1010 1998 1045 2514 19517 22673 2004 1037 2765 1012 1026 7987 1013 1028 1026 7987 1013 1028 2061 2009 1005 1055 1037 2304 4038 2003 2009 1029 2064 3087 2425 2033 2073 1996 17211 2003 1999 26927 13793 1005 1055 3932 1029 2009 1005 1055 5121 5510 3238 1006 1996 5008 1999 1996 2132 1997 1037 14460 1005 1055 2564 2003 2021 2178 10743 5021 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.362660 139892431648640 run_classifier.py:465] input_ids: 101 2809 2914 9930 1029 2009 1005 1055 3458 6772 1012 1045 2064 2069 2228 2009 2001 1037 2200 2919 2095 1011 2130 2011 5365 4781 1012 2007 15876 7106 2004 2472 1998 2990 16955 1998 14559 6769 2004 5260 1045 2763 2052 2031 7351 1996 17395 1998 3427 2023 4312 1010 2021 1996 7436 9930 2428 2853 2009 2000 2033 1010 1998 1045 2514 19517 22673 2004 1037 2765 1012 1026 7987 1013 1028 1026 7987 1013 1028 2061 2009 1005 1055 1037 2304 4038 2003 2009 1029 2064 3087 2425 2033 2073 1996 17211 2003 1999 26927 13793 1005 1055 3932 1029 2009 1005 1055 5121 5510 3238 1006 1996 5008 1999 1996 2132 1997 1037 14460 1005 1055 2564 2003 2021 2178 10743 5021 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.365533 139892431648640 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.368147 139892431648640 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.370546 139892431648640 run_classifier.py:468] label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.379782 139892431648640 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.383041 139892431648640 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] pretty poor fires ##tar ##ter clone that seems more like a bad tv movie than a bad feature film . how disappointing for this to come from hooper and do ##uri ##f ! < br / > < br / > government contractors do a human experiment with a hydrogen bomb . the boy born to the couple from the experiment constantly runs a fever of 100 degrees , and when he ' s an adult , people in his life start spontaneously comb ##ust ##ing . he tries to find out why . < br / > < br / > the people completely on fire are well done , but when they get to the point that they are well done in another sense [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.385696 139892431648640 run_classifier.py:464] tokens: [CLS] pretty poor fires ##tar ##ter clone that seems more like a bad tv movie than a bad feature film . how disappointing for this to come from hooper and do ##uri ##f ! < br / > < br / > government contractors do a human experiment with a hydrogen bomb . the boy born to the couple from the experiment constantly runs a fever of 100 degrees , and when he ' s an adult , people in his life start spontaneously comb ##ust ##ing . he tries to find out why . < br / > < br / > the people completely on fire are well done , but when they get to the point that they are well done in another sense [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3492 3532 8769 7559 3334 17598 2008 3849 2062 2066 1037 2919 2694 3185 2084 1037 2919 3444 2143 1012 2129 15640 2005 2023 2000 2272 2013 23717 1998 2079 9496 2546 999 1026 7987 1013 1028 1026 7987 1013 1028 2231 16728 2079 1037 2529 7551 2007 1037 9732 5968 1012 1996 2879 2141 2000 1996 3232 2013 1996 7551 7887 3216 1037 9016 1997 2531 5445 1010 1998 2043 2002 1005 1055 2019 4639 1010 2111 1999 2010 2166 2707 27491 22863 19966 2075 1012 2002 5363 2000 2424 2041 2339 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 2111 3294 2006 2543 2024 2092 2589 1010 2021 2043 2027 2131 2000 1996 2391 2008 2027 2024 2092 2589 1999 2178 3168 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.388389 139892431648640 run_classifier.py:465] input_ids: 101 3492 3532 8769 7559 3334 17598 2008 3849 2062 2066 1037 2919 2694 3185 2084 1037 2919 3444 2143 1012 2129 15640 2005 2023 2000 2272 2013 23717 1998 2079 9496 2546 999 1026 7987 1013 1028 1026 7987 1013 1028 2231 16728 2079 1037 2529 7551 2007 1037 9732 5968 1012 1996 2879 2141 2000 1996 3232 2013 1996 7551 7887 3216 1037 9016 1997 2531 5445 1010 1998 2043 2002 1005 1055 2019 4639 1010 2111 1999 2010 2166 2707 27491 22863 19966 2075 1012 2002 5363 2000 2424 2041 2339 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 2111 3294 2006 2543 2024 2092 2589 1010 2021 2043 2027 2131 2000 1996 2391 2008 2027 2024 2092 2589 1999 2178 3168 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.391037 139892431648640 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.393388 139892431648640 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.395893 139892431648640 run_classifier.py:468] label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.403817 139892431648640 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.405566 139892431648640 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] this show has been my escape from reality for the past ten years . i will sadly miss it . although atlantis has filled the hole a small bit . < br / > < br / > the last ever episode of sg ##1 ( on television anyway ) was beautifully done . robert wrote something that felt close to reality . as though he was trying to explain what it was like on the set of the show . ( everyone working closely together for such a long time there are bound to up ' s and downs . but over the years they ' ve turned into a family ) . i thought this was a wonderful way to end despite anyone else [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.407924 139892431648640 run_classifier.py:464] tokens: [CLS] this show has been my escape from reality for the past ten years . i will sadly miss it . although atlantis has filled the hole a small bit . < br / > < br / > the last ever episode of sg ##1 ( on television anyway ) was beautifully done . robert wrote something that felt close to reality . as though he was trying to explain what it was like on the set of the show . ( everyone working closely together for such a long time there are bound to up ' s and downs . but over the years they ' ve turned into a family ) . i thought this was a wonderful way to end despite anyone else [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2023 2265 2038 2042 2026 4019 2013 4507 2005 1996 2627 2702 2086 1012 1045 2097 13718 3335 2009 1012 2348 16637 2038 3561 1996 4920 1037 2235 2978 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 2197 2412 2792 1997 22214 2487 1006 2006 2547 4312 1007 2001 17950 2589 1012 2728 2626 2242 2008 2371 2485 2000 4507 1012 2004 2295 2002 2001 2667 2000 4863 2054 2009 2001 2066 2006 1996 2275 1997 1996 2265 1012 1006 3071 2551 4876 2362 2005 2107 1037 2146 2051 2045 2024 5391 2000 2039 1005 1055 1998 12482 1012 2021 2058 1996 2086 2027 1005 2310 2357 2046 1037 2155 1007 1012 1045 2245 2023 2001 1037 6919 2126 2000 2203 2750 3087 2842 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.410308 139892431648640 run_classifier.py:465] input_ids: 101 2023 2265 2038 2042 2026 4019 2013 4507 2005 1996 2627 2702 2086 1012 1045 2097 13718 3335 2009 1012 2348 16637 2038 3561 1996 4920 1037 2235 2978 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 2197 2412 2792 1997 22214 2487 1006 2006 2547 4312 1007 2001 17950 2589 1012 2728 2626 2242 2008 2371 2485 2000 4507 1012 2004 2295 2002 2001 2667 2000 4863 2054 2009 2001 2066 2006 1996 2275 1997 1996 2265 1012 1006 3071 2551 4876 2362 2005 2107 1037 2146 2051 2045 2024 5391 2000 2039 1005 1055 1998 12482 1012 2021 2058 1996 2086 2027 1005 2310 2357 2046 1037 2155 1007 1012 1045 2245 2023 2001 1037 6919 2126 2000 2203 2750 3087 2842 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.412487 139892431648640 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.414215 139892431648640 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.416712 139892431648640 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.420534 139892431648640 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.422371 139892431648640 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] not a ` woman film ' but film for the gang . one of the worst films ever made by a male director about woman . director andy mckay simply doesn ' t know woman . peaks of bad taste , american pie ' s humor style , crude story , no sense , ground ##less story , ref ##uted characters . vulgar fantasies came to life on screen . insulting and definitely not funny . i wonder how three good actresses accepted to take part in it . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.424813 139892431648640 run_classifier.py:464] tokens: [CLS] not a ` woman film ' but film for the gang . one of the worst films ever made by a male director about woman . director andy mckay simply doesn ' t know woman . peaks of bad taste , american pie ' s humor style , crude story , no sense , ground ##less story , ref ##uted characters . vulgar fantasies came to life on screen . insulting and definitely not funny . i wonder how three good actresses accepted to take part in it . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2025 1037 1036 2450 2143 1005 2021 2143 2005 1996 6080 1012 2028 1997 1996 5409 3152 2412 2081 2011 1037 3287 2472 2055 2450 1012 2472 5557 16225 3432 2987 1005 1056 2113 2450 1012 11373 1997 2919 5510 1010 2137 11345 1005 1055 8562 2806 1010 13587 2466 1010 2053 3168 1010 2598 3238 2466 1010 25416 12926 3494 1012 29364 21233 2234 2000 2166 2006 3898 1012 23979 1998 5791 2025 6057 1012 1045 4687 2129 2093 2204 19910 3970 2000 2202 2112 1999 2009 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.427412 139892431648640 run_classifier.py:465] input_ids: 101 2025 1037 1036 2450 2143 1005 2021 2143 2005 1996 6080 1012 2028 1997 1996 5409 3152 2412 2081 2011 1037 3287 2472 2055 2450 1012 2472 5557 16225 3432 2987 1005 1056 2113 2450 1012 11373 1997 2919 5510 1010 2137 11345 1005 1055 8562 2806 1010 13587 2466 1010 2053 3168 1010 2598 3238 2466 1010 25416 12926 3494 1012 29364 21233 2234 2000 2166 2006 3898 1012 23979 1998 5791 2025 6057 1012 1045 4687 2129 2093 2204 19910 3970 2000 2202 2112 1999 2009 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.430049 139892431648640 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.431828 139892431648640 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.434099 139892431648640 run_classifier.py:468] label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.443534 139892431648640 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.446154 139892431648640 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i can ' t understand why so many peoples praised this show . twin peaks is one of the most boring titles i have ever seen in my life . < br / > < br / > now i have seen all season 1 episodes , and seeing season 2 episode 1 . simply i can ' t take this show anymore . < br / > < br / > 1 ) where is the proper induction in criminal investigation ? < br / > < br / > in season 1 , there was a scene that agent cooper throws stones to a bottle . can you guess why he did that ? he just want to identify murderer by doing this ' [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.448562 139892431648640 run_classifier.py:464] tokens: [CLS] i can ' t understand why so many peoples praised this show . twin peaks is one of the most boring titles i have ever seen in my life . < br / > < br / > now i have seen all season 1 episodes , and seeing season 2 episode 1 . simply i can ' t take this show anymore . < br / > < br / > 1 ) where is the proper induction in criminal investigation ? < br / > < br / > in season 1 , there was a scene that agent cooper throws stones to a bottle . can you guess why he did that ? he just want to identify murderer by doing this ' [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2064 1005 1056 3305 2339 2061 2116 7243 5868 2023 2265 1012 5519 11373 2003 2028 1997 1996 2087 11771 4486 1045 2031 2412 2464 1999 2026 2166 1012 1026 7987 1013 1028 1026 7987 1013 1028 2085 1045 2031 2464 2035 2161 1015 4178 1010 1998 3773 2161 1016 2792 1015 1012 3432 1045 2064 1005 1056 2202 2023 2265 4902 1012 1026 7987 1013 1028 1026 7987 1013 1028 1015 1007 2073 2003 1996 5372 15946 1999 4735 4812 1029 1026 7987 1013 1028 1026 7987 1013 1028 1999 2161 1015 1010 2045 2001 1037 3496 2008 4005 6201 11618 6386 2000 1037 5835 1012 2064 2017 3984 2339 2002 2106 2008 1029 2002 2074 2215 2000 6709 13422 2011 2725 2023 1005 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.451127 139892431648640 run_classifier.py:465] input_ids: 101 1045 2064 1005 1056 3305 2339 2061 2116 7243 5868 2023 2265 1012 5519 11373 2003 2028 1997 1996 2087 11771 4486 1045 2031 2412 2464 1999 2026 2166 1012 1026 7987 1013 1028 1026 7987 1013 1028 2085 1045 2031 2464 2035 2161 1015 4178 1010 1998 3773 2161 1016 2792 1015 1012 3432 1045 2064 1005 1056 2202 2023 2265 4902 1012 1026 7987 1013 1028 1026 7987 1013 1028 1015 1007 2073 2003 1996 5372 15946 1999 4735 4812 1029 1026 7987 1013 1028 1026 7987 1013 1028 1999 2161 1015 1010 2045 2001 1037 3496 2008 4005 6201 11618 6386 2000 1037 5835 1012 2064 2017 3984 2339 2002 2106 2008 1029 2002 2074 2215 2000 6709 13422 2011 2725 2023 1005 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.453707 139892431648640 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.456358 139892431648640 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:37:45.459063 139892431648640 run_classifier.py:468] label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.416994 139892431648640 run_classifier.py:774] Writing example 0 of 5000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.435651 139892431648640 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.437436 139892431648640 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the un ##thi ##nka ##ble has happened . having first witnessed it a few years ago , i have had a film that has been my bench ##mark for awful ##ness and that film was called \" mcc ##ins ##ey ' s island \" . a family adventure movie with hulk hogan and grace jones ( i ' m not making this up ) , it plunged to new depths of movie making and is still the only film i ' ve seen that made me wonder what else the film ' s budget could have been spent on . like new schools or cancer - treating drugs . however , for sheer and una ##du ##lter ##ated levels of crap , any film will be [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.439385 139892431648640 run_classifier.py:464] tokens: [CLS] the un ##thi ##nka ##ble has happened . having first witnessed it a few years ago , i have had a film that has been my bench ##mark for awful ##ness and that film was called \" mcc ##ins ##ey ' s island \" . a family adventure movie with hulk hogan and grace jones ( i ' m not making this up ) , it plunged to new depths of movie making and is still the only film i ' ve seen that made me wonder what else the film ' s budget could have been spent on . like new schools or cancer - treating drugs . however , for sheer and una ##du ##lter ##ated levels of crap , any film will be [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 4895 15222 25804 3468 2038 3047 1012 2383 2034 9741 2009 1037 2261 2086 3283 1010 1045 2031 2018 1037 2143 2008 2038 2042 2026 6847 10665 2005 9643 2791 1998 2008 2143 2001 2170 1000 23680 7076 3240 1005 1055 2479 1000 1012 1037 2155 6172 3185 2007 16009 14851 1998 4519 3557 1006 1045 1005 1049 2025 2437 2023 2039 1007 1010 2009 16687 2000 2047 11143 1997 3185 2437 1998 2003 2145 1996 2069 2143 1045 1005 2310 2464 2008 2081 2033 4687 2054 2842 1996 2143 1005 1055 5166 2071 2031 2042 2985 2006 1012 2066 2047 2816 2030 4456 1011 12318 5850 1012 2174 1010 2005 11591 1998 14477 8566 21928 4383 3798 1997 10231 1010 2151 2143 2097 2022 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.440951 139892431648640 run_classifier.py:465] input_ids: 101 1996 4895 15222 25804 3468 2038 3047 1012 2383 2034 9741 2009 1037 2261 2086 3283 1010 1045 2031 2018 1037 2143 2008 2038 2042 2026 6847 10665 2005 9643 2791 1998 2008 2143 2001 2170 1000 23680 7076 3240 1005 1055 2479 1000 1012 1037 2155 6172 3185 2007 16009 14851 1998 4519 3557 1006 1045 1005 1049 2025 2437 2023 2039 1007 1010 2009 16687 2000 2047 11143 1997 3185 2437 1998 2003 2145 1996 2069 2143 1045 1005 2310 2464 2008 2081 2033 4687 2054 2842 1996 2143 1005 1055 5166 2071 2031 2042 2985 2006 1012 2066 2047 2816 2030 4456 1011 12318 5850 1012 2174 1010 2005 11591 1998 14477 8566 21928 4383 3798 1997 10231 1010 2151 2143 2097 2022 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.443240 139892431648640 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.447095 139892431648640 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.448938 139892431648640 run_classifier.py:468] label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.458796 139892431648640 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.460994 139892431648640 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i have to admit that i had low expectations for this movie . but i was surprised to find it entertaining , interesting , and funny . it ' s an entertaining thriller and not so much a horror film . there were moments that made my hairs stand up ! even better , though , were the highly amusing , occasionally hysterical , comedic moments in the film ( you ' ll know which ones i ' m talking about ) . there also are a few great special effects ( and the humor and the special effects aren ' t necessarily separate ) . < br / > < br / > the acting , on the whole , is very good - - [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.462953 139892431648640 run_classifier.py:464] tokens: [CLS] i have to admit that i had low expectations for this movie . but i was surprised to find it entertaining , interesting , and funny . it ' s an entertaining thriller and not so much a horror film . there were moments that made my hairs stand up ! even better , though , were the highly amusing , occasionally hysterical , comedic moments in the film ( you ' ll know which ones i ' m talking about ) . there also are a few great special effects ( and the humor and the special effects aren ' t necessarily separate ) . < br / > < br / > the acting , on the whole , is very good - - [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2031 2000 6449 2008 1045 2018 2659 10908 2005 2023 3185 1012 2021 1045 2001 4527 2000 2424 2009 14036 1010 5875 1010 1998 6057 1012 2009 1005 1055 2019 14036 10874 1998 2025 2061 2172 1037 5469 2143 1012 2045 2020 5312 2008 2081 2026 13606 3233 2039 999 2130 2488 1010 2295 1010 2020 1996 3811 19142 1010 5681 25614 1010 21699 5312 1999 1996 2143 1006 2017 1005 2222 2113 2029 3924 1045 1005 1049 3331 2055 1007 1012 2045 2036 2024 1037 2261 2307 2569 3896 1006 1998 1996 8562 1998 1996 2569 3896 4995 1005 1056 9352 3584 1007 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 3772 1010 2006 1996 2878 1010 2003 2200 2204 1011 1011 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.466017 139892431648640 run_classifier.py:465] input_ids: 101 1045 2031 2000 6449 2008 1045 2018 2659 10908 2005 2023 3185 1012 2021 1045 2001 4527 2000 2424 2009 14036 1010 5875 1010 1998 6057 1012 2009 1005 1055 2019 14036 10874 1998 2025 2061 2172 1037 5469 2143 1012 2045 2020 5312 2008 2081 2026 13606 3233 2039 999 2130 2488 1010 2295 1010 2020 1996 3811 19142 1010 5681 25614 1010 21699 5312 1999 1996 2143 1006 2017 1005 2222 2113 2029 3924 1045 1005 1049 3331 2055 1007 1012 2045 2036 2024 1037 2261 2307 2569 3896 1006 1998 1996 8562 1998 1996 2569 3896 4995 1005 1056 9352 3584 1007 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 3772 1010 2006 1996 2878 1010 2003 2200 2204 1011 1011 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.468036 139892431648640 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.470876 139892431648640 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.473743 139892431648640 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.489240 139892431648640 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.491460 139892431648640 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i hate movies that end like this ! ! ! ! < br / > < br / > this 16 ##mm disaster is full of cl ##iche ##s , stereo ##typical characters , a generic , over done \" plot \" and terrible dial ##og . < br / > < br / > in this \" movie \" we have the aggressive black guy , the black guys girlfriend , the blonde bitch , the possible lesbian \" hacker chick \" , the pe ##do ##phi ##lic teacher . . . blah , blah , blah . . . . and then the pumpkin man . < br / > < br / > \" do you think someone is taking the legend too [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.494598 139892431648640 run_classifier.py:464] tokens: [CLS] i hate movies that end like this ! ! ! ! < br / > < br / > this 16 ##mm disaster is full of cl ##iche ##s , stereo ##typical characters , a generic , over done \" plot \" and terrible dial ##og . < br / > < br / > in this \" movie \" we have the aggressive black guy , the black guys girlfriend , the blonde bitch , the possible lesbian \" hacker chick \" , the pe ##do ##phi ##lic teacher . . . blah , blah , blah . . . . and then the pumpkin man . < br / > < br / > \" do you think someone is taking the legend too [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 5223 5691 2008 2203 2066 2023 999 999 999 999 1026 7987 1013 1028 1026 7987 1013 1028 2023 2385 7382 7071 2003 2440 1997 18856 17322 2015 1010 12991 27086 3494 1010 1037 12391 1010 2058 2589 1000 5436 1000 1998 6659 13764 8649 1012 1026 7987 1013 1028 1026 7987 1013 1028 1999 2023 1000 3185 1000 2057 2031 1996 9376 2304 3124 1010 1996 2304 4364 6513 1010 1996 9081 7743 1010 1996 2825 11690 1000 23307 14556 1000 1010 1996 21877 3527 21850 10415 3836 1012 1012 1012 27984 1010 27984 1010 27984 1012 1012 1012 1012 1998 2059 1996 25730 2158 1012 1026 7987 1013 1028 1026 7987 1013 1028 1000 2079 2017 2228 2619 2003 2635 1996 5722 2205 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.496844 139892431648640 run_classifier.py:465] input_ids: 101 1045 5223 5691 2008 2203 2066 2023 999 999 999 999 1026 7987 1013 1028 1026 7987 1013 1028 2023 2385 7382 7071 2003 2440 1997 18856 17322 2015 1010 12991 27086 3494 1010 1037 12391 1010 2058 2589 1000 5436 1000 1998 6659 13764 8649 1012 1026 7987 1013 1028 1026 7987 1013 1028 1999 2023 1000 3185 1000 2057 2031 1996 9376 2304 3124 1010 1996 2304 4364 6513 1010 1996 9081 7743 1010 1996 2825 11690 1000 23307 14556 1000 1010 1996 21877 3527 21850 10415 3836 1012 1012 1012 27984 1010 27984 1010 27984 1012 1012 1012 1012 1998 2059 1996 25730 2158 1012 1026 7987 1013 1028 1026 7987 1013 1028 1000 2079 2017 2228 2619 2003 2635 1996 5722 2205 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.500162 139892431648640 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.502411 139892431648640 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.504413 139892431648640 run_classifier.py:468] label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.514573 139892431648640 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.518325 139892431648640 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i was invited to view this film at a small art museum screening . i had no clue what to expect . i was initially optimistic in the opening credits to see judd nelson , bill paxton , wayne newton , james can ##n , rob lowe , and lara - flynn - boyle listed . however after some very disturbing grossed - out scenes ( that did not add much to the story advancement ) , this film quickly became a weapon of torture . the gi ##mm ##ick of the vest ##ig ##ial growing arm storyline is never really developed . i patiently kept waiting for this film to cash - in . there was a small pay ##off in the end , but [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.521122 139892431648640 run_classifier.py:464] tokens: [CLS] i was invited to view this film at a small art museum screening . i had no clue what to expect . i was initially optimistic in the opening credits to see judd nelson , bill paxton , wayne newton , james can ##n , rob lowe , and lara - flynn - boyle listed . however after some very disturbing grossed - out scenes ( that did not add much to the story advancement ) , this film quickly became a weapon of torture . the gi ##mm ##ick of the vest ##ig ##ial growing arm storyline is never really developed . i patiently kept waiting for this film to cash - in . there was a small pay ##off in the end , but [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2001 4778 2000 3193 2023 2143 2012 1037 2235 2396 2688 11326 1012 1045 2018 2053 9789 2054 2000 5987 1012 1045 2001 3322 21931 1999 1996 3098 6495 2000 2156 20128 5912 1010 3021 27765 1010 6159 8446 1010 2508 2064 2078 1010 6487 14086 1010 1998 13679 1011 13259 1011 16694 3205 1012 2174 2044 2070 2200 14888 17500 1011 2041 5019 1006 2008 2106 2025 5587 2172 2000 1996 2466 12607 1007 1010 2023 2143 2855 2150 1037 5195 1997 8639 1012 1996 21025 7382 6799 1997 1996 17447 8004 4818 3652 2849 9994 2003 2196 2428 2764 1012 1045 19080 2921 3403 2005 2023 2143 2000 5356 1011 1999 1012 2045 2001 1037 2235 3477 7245 1999 1996 2203 1010 2021 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.524513 139892431648640 run_classifier.py:465] input_ids: 101 1045 2001 4778 2000 3193 2023 2143 2012 1037 2235 2396 2688 11326 1012 1045 2018 2053 9789 2054 2000 5987 1012 1045 2001 3322 21931 1999 1996 3098 6495 2000 2156 20128 5912 1010 3021 27765 1010 6159 8446 1010 2508 2064 2078 1010 6487 14086 1010 1998 13679 1011 13259 1011 16694 3205 1012 2174 2044 2070 2200 14888 17500 1011 2041 5019 1006 2008 2106 2025 5587 2172 2000 1996 2466 12607 1007 1010 2023 2143 2855 2150 1037 5195 1997 8639 1012 1996 21025 7382 6799 1997 1996 17447 8004 4818 3652 2849 9994 2003 2196 2428 2764 1012 1045 19080 2921 3403 2005 2023 2143 2000 5356 1011 1999 1012 2045 2001 1037 2235 3477 7245 1999 1996 2203 1010 2021 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.526784 139892431648640 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.529722 139892431648640 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.531966 139892431648640 run_classifier.py:468] label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.556550 139892431648640 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.558967 139892431648640 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i finally got hold of life ##force on dvd with the wide ##screen format intact and ro ##using henry man ##cini score to the max . after having viewed life ##force for fifteen years on tape , i have to say that the ' un ##cut ' dvd version was both great and disappointing . the u . s . version is so * much * better than the dvd ( european ? ) version . the u . s . version of life ##force moves much faster ( the editing on the dvd version is terrible . feels like an unfinished cut ) . and the many scenes not seen in the american version add little or nothing to the final problem . in fact [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.562061 139892431648640 run_classifier.py:464] tokens: [CLS] i finally got hold of life ##force on dvd with the wide ##screen format intact and ro ##using henry man ##cini score to the max . after having viewed life ##force for fifteen years on tape , i have to say that the ' un ##cut ' dvd version was both great and disappointing . the u . s . version is so * much * better than the dvd ( european ? ) version . the u . s . version of life ##force moves much faster ( the editing on the dvd version is terrible . feels like an unfinished cut ) . and the many scenes not seen in the american version add little or nothing to the final problem . in fact [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2633 2288 2907 1997 2166 14821 2006 4966 2007 1996 2898 18182 4289 10109 1998 20996 18161 2888 2158 27085 3556 2000 1996 4098 1012 2044 2383 7021 2166 14821 2005 5417 2086 2006 6823 1010 1045 2031 2000 2360 2008 1996 1005 4895 12690 1005 4966 2544 2001 2119 2307 1998 15640 1012 1996 1057 1012 1055 1012 2544 2003 2061 1008 2172 1008 2488 2084 1996 4966 1006 2647 1029 1007 2544 1012 1996 1057 1012 1055 1012 2544 1997 2166 14821 5829 2172 5514 1006 1996 9260 2006 1996 4966 2544 2003 6659 1012 5683 2066 2019 14342 3013 1007 1012 1998 1996 2116 5019 2025 2464 1999 1996 2137 2544 5587 2210 2030 2498 2000 1996 2345 3291 1012 1999 2755 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.566314 139892431648640 run_classifier.py:465] input_ids: 101 1045 2633 2288 2907 1997 2166 14821 2006 4966 2007 1996 2898 18182 4289 10109 1998 20996 18161 2888 2158 27085 3556 2000 1996 4098 1012 2044 2383 7021 2166 14821 2005 5417 2086 2006 6823 1010 1045 2031 2000 2360 2008 1996 1005 4895 12690 1005 4966 2544 2001 2119 2307 1998 15640 1012 1996 1057 1012 1055 1012 2544 2003 2061 1008 2172 1008 2488 2084 1996 4966 1006 2647 1029 1007 2544 1012 1996 1057 1012 1055 1012 2544 1997 2166 14821 5829 2172 5514 1006 1996 9260 2006 1996 4966 2544 2003 6659 1012 5683 2066 2019 14342 3013 1007 1012 1998 1996 2116 5019 2025 2464 1999 1996 2137 2544 5587 2210 2030 2498 2000 1996 2345 3291 1012 1999 2755 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.568744 139892431648640 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.571025 139892431648640 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:38:11.574008 139892431648640 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nguid\\ntokens\\ninput_ids\\ninput_mask\\nsegment_ids\\nlabel\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KejM3gP2PsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create model\n",
        "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels, num_labels):\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB, trainable=True)\n",
        "    \n",
        "    bert_inputs = dict(input_ids=input_ids, input_mask= input_mask, segment_ids=segment_ids)\n",
        "    \n",
        "    bert_outputs = bert_module(inputs=bert_inputs, signature='tokens',as_dict=True)\n",
        "    \n",
        "    output_layer = bert_outputs['pooled_output']\n",
        "    \n",
        "    hidden_size = output_layer.shape[-1].value\n",
        "    \n",
        "    output_weights = tf.get_variable('output_weights', [num_labels,hidden_size],initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "    output_bias = tf.get_variable('output_bias', [num_labels],initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "    \n",
        "    # define loss function\n",
        "    with tf.variable_scope(\"loss\"):\n",
        "        output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "        \n",
        "        logits = tf.matmul(output_layer,output_weights, transpose_b=True)\n",
        "        logits = tf.nn.bias_add(logits,output_bias)\n",
        "        log_probs = tf.nn.log_softmax(logits, axis=-1) #logit not logarithmic\n",
        "        \n",
        "        one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "        predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "        \n",
        "        if is_predicting:\n",
        "            return (predicted_labels, log_probs)\n",
        "        \n",
        "        per_example_loss = tf.reduce_sum(one_hot_labels*log_probs, axis=-1)\n",
        "        loss = tf.reduce_mean(per_example_loss)\n",
        "        return (loss,predicted_labels, log_probs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf4ngDps39Gk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_fn_builder(num_labels, learning_rate, num_train_steps,num_warmup_steps):\n",
        "    def model_fn(features, labels, mode, params):\n",
        "        input_ids = features[\"input_ids\"]\n",
        "        input_mask = features[\"input_mask\"]\n",
        "        segment_ids = features[\"segment_ids\"]\n",
        "        label_ids = features[\"label_ids\"]\n",
        "\n",
        "\n",
        "        \n",
        "        is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "        \n",
        "        if not is_predicting:\n",
        "            (loss,predicted_labels,log_probs) = create_model(is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "            \n",
        "            train_op = bert.optimization.create_optimizer(loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "            \n",
        "            def metric_fn(label_ids, predicted_labels):\n",
        "                \n",
        "                accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "                f1_score = tf.contrib.metrics.f1_score(label_ids, predicted_labels)\n",
        "                auc = tf.metrics.auc(label_ids, predicted_labels)\n",
        "                recall = tf.metrics.recall(label_ids, predicted_labels)\n",
        "                precision = tf.metrics.precision(label_ids, predicted_labels)\n",
        "                true_positive = tf.metrics.true_positives(label_ids, predicted_labels)\n",
        "                true_negative = tf.metrics.true_negatives(label_ids, predicted_labels)\n",
        "                false_positive = tf.metrics.false_positives(label_ids, predicted_labels)\n",
        "                false_negative = tf.metrics.false_negatives(label_ids, predicted_labels)\n",
        "                return {\"accuracy\":accuracy,\n",
        "                       \"f1_score\":f1_score,\n",
        "                       \"auc\": auc,\n",
        "                       \"precision\":precision,\n",
        "                       \"true_positive\":true_positive,\n",
        "                       \"true_negative\":true_negative,\n",
        "                       \"false_positive\": false_positive,\n",
        "                       \"false_negative\": false_negative\n",
        "                       }            \n",
        "            eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "            \n",
        "            if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "                \n",
        "                return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
        "            else:\n",
        "                return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metrics)\n",
        "        else:\n",
        "            (loss,predicted_labels, log_probs) = create_model(is_predicting, input_ids, input_mask, segment_ids, labels, num_labels)\n",
        "            predictions = {'probabilities':log_probs, 'labels':predicted_labels}\n",
        "    \n",
        "    return model_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQZXRc3f9T5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAINING_EPOCHS = 3\n",
        "\n",
        "# warm up\n",
        "\n",
        "WARMUP_PROPORTION = 0.1\n",
        "SAVE_CHECKPOINT_STEPS = 500\n",
        "SAVE_SUMMARY_STEPS = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uiHwwsj3ykx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_train_steps = int(len(train_features)/ BATCH_SIZE * NUM_TRAINING_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps* WARMUP_PROPORTION)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RKX_wSc20TA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run_config = tf.estimator.RunConfig(model_dir=OUTPUT_DIR, save_summary_steps=SAVE_SUMMARY_STEPS,save_checkpoints_steps= SAVE_CHECKPOINT_STEPS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBlood8w3GFq",
        "colab_type": "code",
        "outputId": "a009b5c6-2cb0-477d-bea7-4f34c750d716",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "model_fn = model_fn_builder(num_labels=len(label_list), learning_rate=LEARNING_RATE, num_train_steps=num_train_steps, num_warmup_steps=num_warmup_steps)\n",
        "estimator = tf.estimator.Estimator(model_fn=model_fn, config=run_config,params={\"batch_size\": BATCH_SIZE})"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'OUTPUT_DIR_NAME', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3a9ee93ba8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:53:01.798956 139892431648640 estimator.py:201] Using config: {'_model_dir': 'OUTPUT_DIR_NAME', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3a9ee93ba8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf9oCtj04L0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_input_fn = bert.run_classifier.input_fn_builder(\n",
        "    features=train_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsff40ULhdaX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "6ab88f4a-ffb8-4a71-b6b3-aeada0bf8dd8"
      },
      "source": [
        "print(f'Beginning Training!')\n",
        "current_time = datetime.now()\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print(\"Training took time \", datetime.now() - current_time)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning Training!\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:53:06.433850 139892431648640 estimator.py:1111] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:53:10.374153 139892431648640 saver.py:1483] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:53:19.883581 139892431648640 estimator.py:1113] Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:53:19.887528 139892431648640 basic_session_run_hooks.py:527] Create CheckpointSaverHook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:53:24.635890 139892431648640 monitored_session.py:222] Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:53:30.544168 139892431648640 session_manager.py:491] Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:53:30.844308 139892431648640 session_manager.py:493] Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into OUTPUT_DIR_NAME/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:53:41.706232 139892431648640 basic_session_run_hooks.py:594] Saving checkpoints for 0 into OUTPUT_DIR_NAME/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = -0.69408476, step = 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0606 06:54:00.146554 139892431648640 basic_session_run_hooks.py:249] loss = -0.69408476, step = 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.978477\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SyhH0Xf-MOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "estimator.evaluate(input_fn=test_input_fn, steps=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYOxfbpU-PLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIP5yKfmY14a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}