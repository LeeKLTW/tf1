{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predicting Movie Reviews with BERT on TF Hub.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeKLTW/tf1/blob/master/Predicting_Movie_Reviews_with_BERT_on_TF_Hub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kkMQWqUOb-N",
        "colab_type": "code",
        "outputId": "dfc356df-0de0-4c22-bd28-b8994c0f4ff3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from datetime import datetime"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0605 02:54:17.483054 140064389609344 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RE24HacFjYyo",
        "colab_type": "code",
        "outputId": "f1fc7b0f-ae5f-4e24-da5b-2bd0c505f70f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "! pip install bert_tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert_tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 2.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert_tensorflow) (1.12.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0pFKbF1j_E2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bert\n",
        "# from bert import run_classifier\n",
        "# from bert import optimization\n",
        "# from bert import tokenization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2aKg2O_kpfu",
        "colab_type": "code",
        "outputId": "b826f0ca-ebd7-46a5-9e36-36d65907c14a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "OUTPUT_DIR = 'OUTPUT_DIR_NAME'\n",
        "try:\n",
        "    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
        "except:\n",
        "    pass\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: OUTPUT_DIR_NAME *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdWmDkCgxzkw",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "aclImdb\n",
        "├── README\n",
        "├── imdb.vocab\n",
        "├── imdbEr.txt\n",
        "├── test\n",
        "│   ├── labeledBow.feat\n",
        "│   ├── neg\n",
        "│   ├── pos\n",
        "│   ├── urls_neg.txt\n",
        "│   └── urls_pos.txt\n",
        "└── train\n",
        "    ├── labeledBow.feat\n",
        "    ├── neg\n",
        "    ├── pos\n",
        "    ├── unsup\n",
        "    ├── unsupBow.feat\n",
        "    ├── urls_neg.txt\n",
        "    ├── urls_pos.txt\n",
        "    └── urls_unsup.txt\n",
        "  \n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEpltVWOkqn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "import os\n",
        "import re\n",
        "\n",
        "def load_directory_data(directory):\n",
        "    data = {}\n",
        "    data[\"sentence\"] = []\n",
        "    data[\"sentiment\"] = []\n",
        "    \n",
        "    for file_path in os.listdir(directory):\n",
        "        with tf.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
        "            data[\"sentence\"].append(f.read())\n",
        "            data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
        "    data = pd.DataFrame.from_dict(data)\n",
        "    return data\n",
        "\n",
        "def load_dataset(directory):\n",
        "    pos_df = load_directory_data(os.path.join(directory,\"pos\"))\n",
        "    neg_df = load_directory_data(os.path.join(directory,\"neg\"))\n",
        "    pos_df['polarity'] = 1\n",
        "    neg_df['polarity'] = 0\n",
        "    data = pd.concat([pos_df, neg_df]).sample(frac=1.).reset_index(drop=True)\n",
        "    return data\n",
        "    \n",
        "def download_and_load_datasets(force_download=False):\n",
        "    dataset = keras.utils.get_file(fname=\"aclImdb.tar.gz\",\n",
        "                                   origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", extract=True)\n",
        "    train_df = load_dataset(os.path.join(os.path.dirname(dataset), \"aclImdb\", \"train\"))\n",
        "    test_df = load_dataset(os.path.join(os.path.dirname(dataset), \"aclImdb\", \"test\"))\n",
        "    return train_df, test_df\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adlDAJZak47v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df, test_df = download_and_load_datasets()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVqnvG4wwd3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = train_df.sample(5000)\n",
        "test_data = test_df.sample(5000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqkOV5cnzT80",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8232bf59-0010-4043-90ee-69c0d1763273"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2078</th>\n",
              "      <td>Just given the fact that it is based on the mo...</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19596</th>\n",
              "      <td>The film opens with Bill Coles (Melvyn Douglas...</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21368</th>\n",
              "      <td>It's rare that I come across a film this awful...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19951</th>\n",
              "      <td>Very poor effort that offers pretty much nothi...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17765</th>\n",
              "      <td>Be careful with this one. Once you get yer mit...</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                sentence sentiment  polarity\n",
              "2078   Just given the fact that it is based on the mo...         9         1\n",
              "19596  The film opens with Bill Coles (Melvyn Douglas...         8         1\n",
              "21368  It's rare that I come across a film this awful...         1         0\n",
              "19951  Very poor effort that offers pretty much nothi...         3         0\n",
              "17765  Be careful with this one. Once you get yer mit...        10         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71Lj4SWmztVy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e94686d3-df2a-4612-f65e-2d78f25d44f4"
      },
      "source": [
        "test_data.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19267</th>\n",
              "      <td>I hate to admit it, but they were right to sac...</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23314</th>\n",
              "      <td>1930's comedy mystery about \"The Crooked Circl...</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18116</th>\n",
              "      <td>I remember seeing this movie 34 years ago and ...</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23726</th>\n",
              "      <td>Whoever plays the part of J. Douglas Williamso...</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23014</th>\n",
              "      <td>Detective Burt Williams has been on the trail ...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                sentence sentiment  polarity\n",
              "19267  I hate to admit it, but they were right to sac...         4         0\n",
              "23314  1930's comedy mystery about \"The Crooked Circl...         7         1\n",
              "18116  I remember seeing this movie 34 years ago and ...        10         1\n",
              "23726  Whoever plays the part of J. Douglas Williamso...         9         1\n",
              "23014  Detective Burt Williams has been on the trail ...         3         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9PX0YbHk5ec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_COLUMN = 'sentence'\n",
        "LABEL_COLUMN = 'polarity'\n",
        "label_list = [0,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUHSGjL8k5ph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# bert.run_classifier.InputExample\n",
        "train_input_example = train_data.apply(lambda x:bert.run_classifier.InputExample(guid=None, text_a = x[DATA_COLUMN], text_b=None,label=x[LABEL_COLUMN]),axis=1)\n",
        "test_input_example = test_data.apply(lambda x:bert.run_classifier.InputExample(guid=None, text_a = x[DATA_COLUMN], text_b=None,label=x[LABEL_COLUMN]),axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ccqq1ohk50w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5da5f8a5-ad71-40f8-a81e-5b9738b9bde9"
      },
      "source": [
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "def create_tokenizer_from_hub_module():\n",
        "    with tf.Graph().as_default():\n",
        "        bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "        with tf.Session() as sess:\n",
        "            vocab_file, do_lower_case =sess.run([tokenization_info[\"vocab_file\"],tokenization_info[\"do_lower_case\"]])\n",
        "            \n",
        "            return bert.tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:45:00.023222 140064389609344 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQmQiIU09UuC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "1751b537-ce4c-4072-9f95-1f1f8fbf63fb"
      },
      "source": [
        "tokenizer.tokenize(\"This here's an example of using the BERT tokenizer\")"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this',\n",
              " 'here',\n",
              " \"'\",\n",
              " 's',\n",
              " 'an',\n",
              " 'example',\n",
              " 'of',\n",
              " 'using',\n",
              " 'the',\n",
              " 'bert',\n",
              " 'token',\n",
              " '##izer']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpIs_40w9lKS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2502
        },
        "outputId": "48c37857-de33-4c00-bd29-d5f8813d630e"
      },
      "source": [
        "MAX_SEQ_LEN = 128\n",
        "train_feature = bert.run_classifier.convert_examples_to_features(train_input_example, label_list, MAX_SEQ_LEN, tokenizer)\n",
        "test_feature = bert.run_classifier.convert_examples_to_features(test_input_example, label_list, MAX_SEQ_LEN, tokenizer)\n",
        "# This function is not used by this file but is still used by the Colab and people who depend on it.\n",
        "\"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
        "\"\"\"\n",
        "guid\n",
        "tokens\n",
        "input_ids\n",
        "input_mask\n",
        "segment_ids\n",
        "label\n",
        "\"\"\""
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.631971 140064389609344 run_classifier.py:774] Writing example 0 of 5000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.646920 140064389609344 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.650349 140064389609344 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] just given the fact that it is based on the most infamous mass suicide incident of modern times would have been enough to give this 2 - part 1980 made - for - tv film attention . but the fact is that it is a superb recreation of the life of the rev . jim jones , who built a church into a virtual empire , and then encouraged it to di ##sin ##te ##grate into a sl ##ea ##zy cult in which a congressman and his entourage were assassinated , and 91 ##7 cult followers committed suicide by drinking ko ##ol - aid do ##used with cy ##ani ##de . < br / > < br / > done very taste ##fully but ho ##rri [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.654907 140064389609344 run_classifier.py:464] tokens: [CLS] just given the fact that it is based on the most infamous mass suicide incident of modern times would have been enough to give this 2 - part 1980 made - for - tv film attention . but the fact is that it is a superb recreation of the life of the rev . jim jones , who built a church into a virtual empire , and then encouraged it to di ##sin ##te ##grate into a sl ##ea ##zy cult in which a congressman and his entourage were assassinated , and 91 ##7 cult followers committed suicide by drinking ko ##ol - aid do ##used with cy ##ani ##de . < br / > < br / > done very taste ##fully but ho ##rri [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2074 2445 1996 2755 2008 2009 2003 2241 2006 1996 2087 14429 3742 5920 5043 1997 2715 2335 2052 2031 2042 2438 2000 2507 2023 1016 1011 2112 3150 2081 1011 2005 1011 2694 2143 3086 1012 2021 1996 2755 2003 2008 2009 2003 1037 21688 8640 1997 1996 2166 1997 1996 7065 1012 3958 3557 1010 2040 2328 1037 2277 2046 1037 7484 3400 1010 1998 2059 6628 2009 2000 4487 11493 2618 22780 2046 1037 22889 5243 9096 8754 1999 2029 1037 12295 1998 2010 25342 2020 16370 1010 1998 6205 2581 8754 8771 5462 5920 2011 5948 12849 4747 1011 4681 2079 13901 2007 22330 7088 3207 1012 1026 7987 1013 1028 1026 7987 1013 1028 2589 2200 5510 7699 2021 7570 18752 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.657658 140064389609344 run_classifier.py:465] input_ids: 101 2074 2445 1996 2755 2008 2009 2003 2241 2006 1996 2087 14429 3742 5920 5043 1997 2715 2335 2052 2031 2042 2438 2000 2507 2023 1016 1011 2112 3150 2081 1011 2005 1011 2694 2143 3086 1012 2021 1996 2755 2003 2008 2009 2003 1037 21688 8640 1997 1996 2166 1997 1996 7065 1012 3958 3557 1010 2040 2328 1037 2277 2046 1037 7484 3400 1010 1998 2059 6628 2009 2000 4487 11493 2618 22780 2046 1037 22889 5243 9096 8754 1999 2029 1037 12295 1998 2010 25342 2020 16370 1010 1998 6205 2581 8754 8771 5462 5920 2011 5948 12849 4747 1011 4681 2079 13901 2007 22330 7088 3207 1012 1026 7987 1013 1028 1026 7987 1013 1028 2589 2200 5510 7699 2021 7570 18752 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.664347 140064389609344 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.665930 140064389609344 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.667476 140064389609344 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.677038 140064389609344 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.678738 140064389609344 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the film opens with bill cole ##s ( mel ##vyn douglas ) telling a story about how his best friend - - make that client - - jim bland ##ings ( cary grant ) and his family are tightly packed into a small new york apartment , with not enough closet space and way too few bathrooms . when jim ' s wife , muriel ( my ##rna lo ##y ) , wants to reno ##vate the apartment , advertising ex ##ec jim falls in love with ( or falls for ! ) an ad for a house . once he ' s purchased the house , bills and frustration pile up inc ##ess ##antly as everything that can go wrong with the building of jim [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.680067 140064389609344 run_classifier.py:464] tokens: [CLS] the film opens with bill cole ##s ( mel ##vyn douglas ) telling a story about how his best friend - - make that client - - jim bland ##ings ( cary grant ) and his family are tightly packed into a small new york apartment , with not enough closet space and way too few bathrooms . when jim ' s wife , muriel ( my ##rna lo ##y ) , wants to reno ##vate the apartment , advertising ex ##ec jim falls in love with ( or falls for ! ) an ad for a house . once he ' s purchased the house , bills and frustration pile up inc ##ess ##antly as everything that can go wrong with the building of jim [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 2143 7480 2007 3021 5624 2015 1006 11463 23487 5203 1007 4129 1037 2466 2055 2129 2010 2190 2767 1011 1011 2191 2008 7396 1011 1011 3958 20857 8613 1006 20533 3946 1007 1998 2010 2155 2024 7371 8966 2046 1037 2235 2047 2259 4545 1010 2007 2025 2438 9346 2686 1998 2126 2205 2261 28942 1012 2043 3958 1005 1055 2564 1010 27616 1006 2026 12789 8840 2100 1007 1010 4122 2000 17738 16952 1996 4545 1010 6475 4654 8586 3958 4212 1999 2293 2007 1006 2030 4212 2005 999 1007 2019 4748 2005 1037 2160 1012 2320 2002 1005 1055 4156 1996 2160 1010 8236 1998 9135 8632 2039 4297 7971 15706 2004 2673 2008 2064 2175 3308 2007 1996 2311 1997 3958 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.681611 140064389609344 run_classifier.py:465] input_ids: 101 1996 2143 7480 2007 3021 5624 2015 1006 11463 23487 5203 1007 4129 1037 2466 2055 2129 2010 2190 2767 1011 1011 2191 2008 7396 1011 1011 3958 20857 8613 1006 20533 3946 1007 1998 2010 2155 2024 7371 8966 2046 1037 2235 2047 2259 4545 1010 2007 2025 2438 9346 2686 1998 2126 2205 2261 28942 1012 2043 3958 1005 1055 2564 1010 27616 1006 2026 12789 8840 2100 1007 1010 4122 2000 17738 16952 1996 4545 1010 6475 4654 8586 3958 4212 1999 2293 2007 1006 2030 4212 2005 999 1007 2019 4748 2005 1037 2160 1012 2320 2002 1005 1055 4156 1996 2160 1010 8236 1998 9135 8632 2039 4297 7971 15706 2004 2673 2008 2064 2175 3308 2007 1996 2311 1997 3958 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.683230 140064389609344 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.684601 140064389609344 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.685783 140064389609344 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.693044 140064389609344 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.694369 140064389609344 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] it ' s rare that i come across a film this awful , this annoying and this irritating . it is without doubt one of the worst films i ' ve ever seen . < br / > < br / > the plot , when it ' s not a blur of confusing and pointless ##ly over flash ##y editing , is lu ##dic ##rous . why did domino become such a bad - ass tough bitch ? because her gold fish died when she was a kid and this \" traumatic \" event left her emotionally stunt ##ed , and hating everyone . when the dialogue is not cl ##iche ##d or ban ##al , it ' s littered with laugh ##able lines such [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.695702 140064389609344 run_classifier.py:464] tokens: [CLS] it ' s rare that i come across a film this awful , this annoying and this irritating . it is without doubt one of the worst films i ' ve ever seen . < br / > < br / > the plot , when it ' s not a blur of confusing and pointless ##ly over flash ##y editing , is lu ##dic ##rous . why did domino become such a bad - ass tough bitch ? because her gold fish died when she was a kid and this \" traumatic \" event left her emotionally stunt ##ed , and hating everyone . when the dialogue is not cl ##iche ##d or ban ##al , it ' s littered with laugh ##able lines such [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2009 1005 1055 4678 2008 1045 2272 2408 1037 2143 2023 9643 1010 2023 15703 1998 2023 29348 1012 2009 2003 2302 4797 2028 1997 1996 5409 3152 1045 1005 2310 2412 2464 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 5436 1010 2043 2009 1005 1055 2025 1037 14819 1997 16801 1998 23100 2135 2058 5956 2100 9260 1010 2003 11320 14808 13288 1012 2339 2106 23968 2468 2107 1037 2919 1011 4632 7823 7743 1029 2138 2014 2751 3869 2351 2043 2016 2001 1037 4845 1998 2023 1000 19686 1000 2724 2187 2014 14868 15412 2098 1010 1998 22650 3071 1012 2043 1996 7982 2003 2025 18856 17322 2094 2030 7221 2389 1010 2009 1005 1055 24777 2007 4756 3085 3210 2107 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.697430 140064389609344 run_classifier.py:465] input_ids: 101 2009 1005 1055 4678 2008 1045 2272 2408 1037 2143 2023 9643 1010 2023 15703 1998 2023 29348 1012 2009 2003 2302 4797 2028 1997 1996 5409 3152 1045 1005 2310 2412 2464 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 5436 1010 2043 2009 1005 1055 2025 1037 14819 1997 16801 1998 23100 2135 2058 5956 2100 9260 1010 2003 11320 14808 13288 1012 2339 2106 23968 2468 2107 1037 2919 1011 4632 7823 7743 1029 2138 2014 2751 3869 2351 2043 2016 2001 1037 4845 1998 2023 1000 19686 1000 2724 2187 2014 14868 15412 2098 1010 1998 22650 3071 1012 2043 1996 7982 2003 2025 18856 17322 2094 2030 7221 2389 1010 2009 1005 1055 24777 2007 4756 3085 3210 2107 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.698824 140064389609344 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.700118 140064389609344 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.701330 140064389609344 run_classifier.py:468] label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.704792 140064389609344 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.706339 140064389609344 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] very poor effort that offers pretty much nothing to anyone but a hardcore fan of stanley tu ##cci , who tries , but can not save the poor structure , dialogue , direction , or talent of our leading man . < br / > < br / > pretty much the only trick this pl ##od ##ding tale of a naive new salesman for an alarm company has , is its qui ##rky side characters . but without a realistic backdrop , such characters are pointless . < br / > < br / > nothing to see here , keep moving . . . < br / > < br / > [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.707774 140064389609344 run_classifier.py:464] tokens: [CLS] very poor effort that offers pretty much nothing to anyone but a hardcore fan of stanley tu ##cci , who tries , but can not save the poor structure , dialogue , direction , or talent of our leading man . < br / > < br / > pretty much the only trick this pl ##od ##ding tale of a naive new salesman for an alarm company has , is its qui ##rky side characters . but without a realistic backdrop , such characters are pointless . < br / > < br / > nothing to see here , keep moving . . . < br / > < br / > [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2200 3532 3947 2008 4107 3492 2172 2498 2000 3087 2021 1037 13076 5470 1997 6156 10722 14693 1010 2040 5363 1010 2021 2064 2025 3828 1996 3532 3252 1010 7982 1010 3257 1010 2030 5848 1997 2256 2877 2158 1012 1026 7987 1013 1028 1026 7987 1013 1028 3492 2172 1996 2069 7577 2023 20228 7716 4667 6925 1997 1037 15743 2047 18968 2005 2019 8598 2194 2038 1010 2003 2049 21864 15952 2217 3494 1012 2021 2302 1037 12689 18876 1010 2107 3494 2024 23100 1012 1026 7987 1013 1028 1026 7987 1013 1028 2498 2000 2156 2182 1010 2562 3048 1012 1012 1012 1026 7987 1013 1028 1026 7987 1013 1028 102 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.709034 140064389609344 run_classifier.py:465] input_ids: 101 2200 3532 3947 2008 4107 3492 2172 2498 2000 3087 2021 1037 13076 5470 1997 6156 10722 14693 1010 2040 5363 1010 2021 2064 2025 3828 1996 3532 3252 1010 7982 1010 3257 1010 2030 5848 1997 2256 2877 2158 1012 1026 7987 1013 1028 1026 7987 1013 1028 3492 2172 1996 2069 7577 2023 20228 7716 4667 6925 1997 1037 15743 2047 18968 2005 2019 8598 2194 2038 1010 2003 2049 21864 15952 2217 3494 1012 2021 2302 1037 12689 18876 1010 2107 3494 2024 23100 1012 1026 7987 1013 1028 1026 7987 1013 1028 2498 2000 2156 2182 1010 2562 3048 1012 1012 1012 1026 7987 1013 1028 1026 7987 1013 1028 102 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.710358 140064389609344 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.711559 140064389609344 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.712787 140064389609344 run_classifier.py:468] label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.720938 140064389609344 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.722469 140064389609344 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] be careful with this one . once you get yer mit ##ts on it , it ' ll change the way you look at kung - fu flick ##s . you will be yearning a plot from all of the kung - fu films now , you will be wanting character depth and development , you will be craving mystery and un ##pre ##dict ##ability , you will demand dynamic camera work and incredible backdrop ##s . sadly , you won ' t find all of these aspects together in one kung - fu movie , except for five deadly venom ##s ! < br / > < br / > easily the best kung - fu movie of all - time , venom ##s blend [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.725441 140064389609344 run_classifier.py:464] tokens: [CLS] be careful with this one . once you get yer mit ##ts on it , it ' ll change the way you look at kung - fu flick ##s . you will be yearning a plot from all of the kung - fu films now , you will be wanting character depth and development , you will be craving mystery and un ##pre ##dict ##ability , you will demand dynamic camera work and incredible backdrop ##s . sadly , you won ' t find all of these aspects together in one kung - fu movie , except for five deadly venom ##s ! < br / > < br / > easily the best kung - fu movie of all - time , venom ##s blend [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2022 6176 2007 2023 2028 1012 2320 2017 2131 20416 10210 3215 2006 2009 1010 2009 1005 2222 2689 1996 2126 2017 2298 2012 18577 1011 11865 17312 2015 1012 2017 2097 2022 29479 1037 5436 2013 2035 1997 1996 18577 1011 11865 3152 2085 1010 2017 2097 2022 5782 2839 5995 1998 2458 1010 2017 2097 2022 26369 6547 1998 4895 28139 29201 8010 1010 2017 2097 5157 8790 4950 2147 1998 9788 18876 2015 1012 13718 1010 2017 2180 1005 1056 2424 2035 1997 2122 5919 2362 1999 2028 18577 1011 11865 3185 1010 3272 2005 2274 9252 15779 2015 999 1026 7987 1013 1028 1026 7987 1013 1028 4089 1996 2190 18577 1011 11865 3185 1997 2035 1011 2051 1010 15779 2015 12586 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.726761 140064389609344 run_classifier.py:465] input_ids: 101 2022 6176 2007 2023 2028 1012 2320 2017 2131 20416 10210 3215 2006 2009 1010 2009 1005 2222 2689 1996 2126 2017 2298 2012 18577 1011 11865 17312 2015 1012 2017 2097 2022 29479 1037 5436 2013 2035 1997 1996 18577 1011 11865 3152 2085 1010 2017 2097 2022 5782 2839 5995 1998 2458 1010 2017 2097 2022 26369 6547 1998 4895 28139 29201 8010 1010 2017 2097 5157 8790 4950 2147 1998 9788 18876 2015 1012 13718 1010 2017 2180 1005 1056 2424 2035 1997 2122 5919 2362 1999 2028 18577 1011 11865 3185 1010 3272 2005 2274 9252 15779 2015 999 1026 7987 1013 1028 1026 7987 1013 1028 4089 1996 2190 18577 1011 11865 3185 1997 2035 1011 2051 1010 15779 2015 12586 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.728109 140064389609344 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.729502 140064389609344 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:01.730834 140064389609344 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.027789 140064389609344 run_classifier.py:774] Writing example 0 of 5000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.039455 140064389609344 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.041100 140064389609344 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i hate to admit it , but they were right to sack sc ##hra ##der . the opportunity is here to build an atmosphere , to draw an audience into a movie . it wasn ' t done . the characters are weak . the story was weak . the directing was very poor . sc ##hra ##der was out of his depth and it shows . i ' ve watched it several times now in the hope that there will be at least one red ##eem ##ing feature . but no , nothing . the next stage will probably be a remake of the original or hopefully it will be left well alone . anyone wanting to know what the best sequel to the ex [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.043261 140064389609344 run_classifier.py:464] tokens: [CLS] i hate to admit it , but they were right to sack sc ##hra ##der . the opportunity is here to build an atmosphere , to draw an audience into a movie . it wasn ' t done . the characters are weak . the story was weak . the directing was very poor . sc ##hra ##der was out of his depth and it shows . i ' ve watched it several times now in the hope that there will be at least one red ##eem ##ing feature . but no , nothing . the next stage will probably be a remake of the original or hopefully it will be left well alone . anyone wanting to know what the best sequel to the ex [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 5223 2000 6449 2009 1010 2021 2027 2020 2157 2000 12803 8040 13492 4063 1012 1996 4495 2003 2182 2000 3857 2019 7224 1010 2000 4009 2019 4378 2046 1037 3185 1012 2009 2347 1005 1056 2589 1012 1996 3494 2024 5410 1012 1996 2466 2001 5410 1012 1996 9855 2001 2200 3532 1012 8040 13492 4063 2001 2041 1997 2010 5995 1998 2009 3065 1012 1045 1005 2310 3427 2009 2195 2335 2085 1999 1996 3246 2008 2045 2097 2022 2012 2560 2028 2417 21564 2075 3444 1012 2021 2053 1010 2498 1012 1996 2279 2754 2097 2763 2022 1037 12661 1997 1996 2434 2030 11504 2009 2097 2022 2187 2092 2894 1012 3087 5782 2000 2113 2054 1996 2190 8297 2000 1996 4654 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.045237 140064389609344 run_classifier.py:465] input_ids: 101 1045 5223 2000 6449 2009 1010 2021 2027 2020 2157 2000 12803 8040 13492 4063 1012 1996 4495 2003 2182 2000 3857 2019 7224 1010 2000 4009 2019 4378 2046 1037 3185 1012 2009 2347 1005 1056 2589 1012 1996 3494 2024 5410 1012 1996 2466 2001 5410 1012 1996 9855 2001 2200 3532 1012 8040 13492 4063 2001 2041 1997 2010 5995 1998 2009 3065 1012 1045 1005 2310 3427 2009 2195 2335 2085 1999 1996 3246 2008 2045 2097 2022 2012 2560 2028 2417 21564 2075 3444 1012 2021 2053 1010 2498 1012 1996 2279 2754 2097 2763 2022 1037 12661 1997 1996 2434 2030 11504 2009 2097 2022 2187 2092 2894 1012 3087 5782 2000 2113 2054 1996 2190 8297 2000 1996 4654 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.048739 140064389609344 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.052015 140064389609344 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.055397 140064389609344 run_classifier.py:468] label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.064500 140064389609344 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.066355 140064389609344 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] 1930 ' s comedy mystery about \" the crooked circle \" a band of hooded crook ##s who set about plotting the murder of some one who swore to oppose them . enjoyable but really un ##rem ##ark ##able little film , the movie works simply because the cast headed by za ##zu pitt ##s and james g ##lea ##son ( both of whom would later appear together in a couple of hi ##lde ##gard ##e with ##ers films after edna mae oliver dropped out of that series ) and supported by a great cast of actors and actresses you know but may not know the name of ( i don ' t hence the lack naming ) . a bree ##zy hour long rom ##p [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.068390 140064389609344 run_classifier.py:464] tokens: [CLS] 1930 ' s comedy mystery about \" the crooked circle \" a band of hooded crook ##s who set about plotting the murder of some one who swore to oppose them . enjoyable but really un ##rem ##ark ##able little film , the movie works simply because the cast headed by za ##zu pitt ##s and james g ##lea ##son ( both of whom would later appear together in a couple of hi ##lde ##gard ##e with ##ers films after edna mae oliver dropped out of that series ) and supported by a great cast of actors and actresses you know but may not know the name of ( i don ' t hence the lack naming ) . a bree ##zy hour long rom ##p [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4479 1005 1055 4038 6547 2055 1000 1996 15274 4418 1000 1037 2316 1997 21592 19302 2015 2040 2275 2055 20699 1996 4028 1997 2070 2028 2040 12860 2000 15391 2068 1012 22249 2021 2428 4895 28578 17007 3085 2210 2143 1010 1996 3185 2573 3432 2138 1996 3459 3753 2011 23564 9759 15091 2015 1998 2508 1043 19738 3385 1006 2119 1997 3183 2052 2101 3711 2362 1999 1037 3232 1997 7632 17920 13444 2063 2007 2545 3152 2044 21051 11530 6291 3333 2041 1997 2008 2186 1007 1998 3569 2011 1037 2307 3459 1997 5889 1998 19910 2017 2113 2021 2089 2025 2113 1996 2171 1997 1006 1045 2123 1005 1056 6516 1996 3768 10324 1007 1012 1037 21986 9096 3178 2146 17083 2361 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.070415 140064389609344 run_classifier.py:465] input_ids: 101 4479 1005 1055 4038 6547 2055 1000 1996 15274 4418 1000 1037 2316 1997 21592 19302 2015 2040 2275 2055 20699 1996 4028 1997 2070 2028 2040 12860 2000 15391 2068 1012 22249 2021 2428 4895 28578 17007 3085 2210 2143 1010 1996 3185 2573 3432 2138 1996 3459 3753 2011 23564 9759 15091 2015 1998 2508 1043 19738 3385 1006 2119 1997 3183 2052 2101 3711 2362 1999 1037 3232 1997 7632 17920 13444 2063 2007 2545 3152 2044 21051 11530 6291 3333 2041 1997 2008 2186 1007 1998 3569 2011 1037 2307 3459 1997 5889 1998 19910 2017 2113 2021 2089 2025 2113 1996 2171 1997 1006 1045 2123 1005 1056 6516 1996 3768 10324 1007 1012 1037 21986 9096 3178 2146 17083 2361 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.074283 140064389609344 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.078449 140064389609344 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.082123 140064389609344 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.089720 140064389609344 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.093047 140064389609344 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i remember seeing this movie 34 years ago and it was full of suspense and twists . it grabs you at the beginning and keeps you guessing throughout the whole movie . i have thought about this movie for the past several years and have checked in video stores to see if it ' s available , but was never able to find it or anyone who had even heard of it . i think this type of movie is timeless , and i know it would be enjoyed by a whole new generation of movie watch ##ers . i hope this gets on video soon as it would be fun to see if it has the same impact on me as it did back in [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.096771 140064389609344 run_classifier.py:464] tokens: [CLS] i remember seeing this movie 34 years ago and it was full of suspense and twists . it grabs you at the beginning and keeps you guessing throughout the whole movie . i have thought about this movie for the past several years and have checked in video stores to see if it ' s available , but was never able to find it or anyone who had even heard of it . i think this type of movie is timeless , and i know it would be enjoyed by a whole new generation of movie watch ##ers . i hope this gets on video soon as it would be fun to see if it has the same impact on me as it did back in [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 3342 3773 2023 3185 4090 2086 3283 1998 2009 2001 2440 1997 23873 1998 21438 1012 2009 13273 2017 2012 1996 2927 1998 7906 2017 16986 2802 1996 2878 3185 1012 1045 2031 2245 2055 2023 3185 2005 1996 2627 2195 2086 1998 2031 7039 1999 2678 5324 2000 2156 2065 2009 1005 1055 2800 1010 2021 2001 2196 2583 2000 2424 2009 2030 3087 2040 2018 2130 2657 1997 2009 1012 1045 2228 2023 2828 1997 3185 2003 27768 1010 1998 1045 2113 2009 2052 2022 5632 2011 1037 2878 2047 4245 1997 3185 3422 2545 1012 1045 3246 2023 4152 2006 2678 2574 2004 2009 2052 2022 4569 2000 2156 2065 2009 2038 1996 2168 4254 2006 2033 2004 2009 2106 2067 1999 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.100277 140064389609344 run_classifier.py:465] input_ids: 101 1045 3342 3773 2023 3185 4090 2086 3283 1998 2009 2001 2440 1997 23873 1998 21438 1012 2009 13273 2017 2012 1996 2927 1998 7906 2017 16986 2802 1996 2878 3185 1012 1045 2031 2245 2055 2023 3185 2005 1996 2627 2195 2086 1998 2031 7039 1999 2678 5324 2000 2156 2065 2009 1005 1055 2800 1010 2021 2001 2196 2583 2000 2424 2009 2030 3087 2040 2018 2130 2657 1997 2009 1012 1045 2228 2023 2828 1997 3185 2003 27768 1010 1998 1045 2113 2009 2052 2022 5632 2011 1037 2878 2047 4245 1997 3185 3422 2545 1012 1045 3246 2023 4152 2006 2678 2574 2004 2009 2052 2022 4569 2000 2156 2065 2009 2038 1996 2168 4254 2006 2033 2004 2009 2106 2067 1999 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.103600 140064389609344 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.105764 140064389609344 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.109273 140064389609344 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.125864 140064389609344 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.128798 140064389609344 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] whoever plays the part of j . douglas williamson in the strip poker scene does a wonderful job . he apparently received no credits . too bad . < br / > < br / > all the dead end kids do their jobs beautifully in this 1939 entry . it is odd to watch them in a western setting with their brooklyn accents ( i guess that should be bow ##ery ) . they even show some swimming abilities . < br / > < br / > i think there are many special scenes that can stay with the viewer of this boxing / love / crime story . my favorite right now is in the fight scene near the end of the film [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.131673 140064389609344 run_classifier.py:464] tokens: [CLS] whoever plays the part of j . douglas williamson in the strip poker scene does a wonderful job . he apparently received no credits . too bad . < br / > < br / > all the dead end kids do their jobs beautifully in this 1939 entry . it is odd to watch them in a western setting with their brooklyn accents ( i guess that should be bow ##ery ) . they even show some swimming abilities . < br / > < br / > i think there are many special scenes that can stay with the viewer of this boxing / love / crime story . my favorite right now is in the fight scene near the end of the film [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 9444 3248 1996 2112 1997 1046 1012 5203 14333 1999 1996 6167 11662 3496 2515 1037 6919 3105 1012 2002 4593 2363 2053 6495 1012 2205 2919 1012 1026 7987 1013 1028 1026 7987 1013 1028 2035 1996 2757 2203 4268 2079 2037 5841 17950 1999 2023 3912 4443 1012 2009 2003 5976 2000 3422 2068 1999 1037 2530 4292 2007 2037 6613 24947 1006 1045 3984 2008 2323 2022 6812 7301 1007 1012 2027 2130 2265 2070 5742 7590 1012 1026 7987 1013 1028 1026 7987 1013 1028 1045 2228 2045 2024 2116 2569 5019 2008 2064 2994 2007 1996 13972 1997 2023 8362 1013 2293 1013 4126 2466 1012 2026 5440 2157 2085 2003 1999 1996 2954 3496 2379 1996 2203 1997 1996 2143 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.134109 140064389609344 run_classifier.py:465] input_ids: 101 9444 3248 1996 2112 1997 1046 1012 5203 14333 1999 1996 6167 11662 3496 2515 1037 6919 3105 1012 2002 4593 2363 2053 6495 1012 2205 2919 1012 1026 7987 1013 1028 1026 7987 1013 1028 2035 1996 2757 2203 4268 2079 2037 5841 17950 1999 2023 3912 4443 1012 2009 2003 5976 2000 3422 2068 1999 1037 2530 4292 2007 2037 6613 24947 1006 1045 3984 2008 2323 2022 6812 7301 1007 1012 2027 2130 2265 2070 5742 7590 1012 1026 7987 1013 1028 1026 7987 1013 1028 1045 2228 2045 2024 2116 2569 5019 2008 2064 2994 2007 1996 13972 1997 2023 8362 1013 2293 1013 4126 2466 1012 2026 5440 2157 2085 2003 1999 1996 2954 3496 2379 1996 2203 1997 1996 2143 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.136383 140064389609344 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.138628 140064389609344 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.142713 140064389609344 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.149866 140064389609344 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.152021 140064389609344 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] detective burt williams has been on the trail of the infamous poe killer for nearly three years . burt ' s daughter kris williams , a homicide agent for the fbi along with her partner sean michaels take over . burt reluctantly steps down from the case and retire ##s . for the next seven months the \" poe killer \" continues his murderous rampage until kris discovers that the killer uses internet chat rooms to seduce his prey . she logs in as anna ##bel lee and is quickly captured by poe killer . it ' s time for burt to find the sad ##ist and free his daughter before it ' s too late . amateur ##ish and supreme ##ly brain ##de ##ad horror [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.153950 140064389609344 run_classifier.py:464] tokens: [CLS] detective burt williams has been on the trail of the infamous poe killer for nearly three years . burt ' s daughter kris williams , a homicide agent for the fbi along with her partner sean michaels take over . burt reluctantly steps down from the case and retire ##s . for the next seven months the \" poe killer \" continues his murderous rampage until kris discovers that the killer uses internet chat rooms to seduce his prey . she logs in as anna ##bel lee and is quickly captured by poe killer . it ' s time for burt to find the sad ##ist and free his daughter before it ' s too late . amateur ##ish and supreme ##ly brain ##de ##ad horror [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 6317 18611 3766 2038 2042 2006 1996 4446 1997 1996 14429 18922 6359 2005 3053 2093 2086 1012 18611 1005 1055 2684 19031 3766 1010 1037 18268 4005 2005 1996 8495 2247 2007 2014 4256 5977 17784 2202 2058 1012 18611 11206 4084 2091 2013 1996 2553 1998 11036 2015 1012 2005 1996 2279 2698 2706 1996 1000 18922 6359 1000 4247 2010 25303 29216 2127 19031 9418 2008 1996 6359 3594 4274 11834 4734 2000 23199 2010 8336 1012 2016 15664 1999 2004 4698 8671 3389 1998 2003 2855 4110 2011 18922 6359 1012 2009 1005 1055 2051 2005 18611 2000 2424 1996 6517 2923 1998 2489 2010 2684 2077 2009 1005 1055 2205 2397 1012 5515 4509 1998 4259 2135 4167 3207 4215 5469 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.156123 140064389609344 run_classifier.py:465] input_ids: 101 6317 18611 3766 2038 2042 2006 1996 4446 1997 1996 14429 18922 6359 2005 3053 2093 2086 1012 18611 1005 1055 2684 19031 3766 1010 1037 18268 4005 2005 1996 8495 2247 2007 2014 4256 5977 17784 2202 2058 1012 18611 11206 4084 2091 2013 1996 2553 1998 11036 2015 1012 2005 1996 2279 2698 2706 1996 1000 18922 6359 1000 4247 2010 25303 29216 2127 19031 9418 2008 1996 6359 3594 4274 11834 4734 2000 23199 2010 8336 1012 2016 15664 1999 2004 4698 8671 3389 1998 2003 2855 4110 2011 18922 6359 1012 2009 1005 1055 2051 2005 18611 2000 2424 1996 6517 2923 1998 2489 2010 2684 2077 2009 1005 1055 2205 2397 1012 5515 4509 1998 4259 2135 4167 3207 4215 5469 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.158212 140064389609344 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.160341 140064389609344 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0605 04:59:28.162304 140064389609344 run_classifier.py:468] label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Convert a set of `InputExample`s to a list of `InputFeatures`.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KejM3gP2PsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create model\n",
        "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels, num_labels):\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB, trainable=True)\n",
        "    \n",
        "    # todo: below\n",
        "    bert_inputs = dict()\n",
        "    \n",
        "    bert_outputs = bert_module()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQZXRc3f9T5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uiHwwsj3ykx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RKX_wSc20TA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBlood8w3GFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf9oCtj04L0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}